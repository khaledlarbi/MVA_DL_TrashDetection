{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XSixqNNb_7Z",
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Anchors\" data-toc-modified-id=\"Anchors-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Anchors</a></span></li><li><span><a href=\"#Preparation-of-the-proposed-region-to-train-the-Fast-RCNN\" data-toc-modified-id=\"Preparation-of-the-proposed-region-to-train-the-Fast-RCNN-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Preparation of the proposed region to train the Fast RCNN</a></span></li><li><span><a href=\"#Region-proposal-network\" data-toc-modified-id=\"Region-proposal-network-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Region proposal network</a></span></li><li><span><a href=\"#Load-train-dataset\" data-toc-modified-id=\"Load-train-dataset-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Load train dataset</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Version-4---resize-des-images,-en-ne-gardant-que-les-bbox-et-category_id-des-targets-normalisées,-dans-un-array-de-dictionnaires-(targets-de-taille-variables)\" data-toc-modified-id=\"Version-4---resize-des-images,-en-ne-gardant-que-les-bbox-et-category_id-des-targets-normalisées,-dans-un-array-de-dictionnaires-(targets-de-taille-variables)-4.0.0.1\"><span class=\"toc-item-num\">4.0.0.1&nbsp;&nbsp;</span>Version 4 - resize des images, en ne gardant que les bbox et category_id des targets normalisées, dans un array de dictionnaires (targets de taille variables)</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Training-RPN-network\" data-toc-modified-id=\"Training-RPN-network-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Training RPN network</a></span><ul class=\"toc-item\"><li><span><a href=\"#Split-the-dataset\" data-toc-modified-id=\"Split-the-dataset-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Split the dataset</a></span></li><li><span><a href=\"#Load-previous-trained-Fast-model\" data-toc-modified-id=\"Load-previous-trained-Fast-model-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Load previous trained Fast model</a></span></li><li><span><a href=\"#Continue\" data-toc-modified-id=\"Continue-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Continue</a></span></li><li><span><a href=\"#Transition-between-RPN-and-FastRCNN\" data-toc-modified-id=\"Transition-between-RPN-and-FastRCNN-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Transition between RPN and FastRCNN</a></span></li><li><span><a href=\"#Fast-RCNN\" data-toc-modified-id=\"Fast-RCNN-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Fast RCNN</a></span><ul class=\"toc-item\"><li><span><a href=\"#Losses-for-Fast-RCNN\" data-toc-modified-id=\"Losses-for-Fast-RCNN-5.5.1\"><span class=\"toc-item-num\">5.5.1&nbsp;&nbsp;</span>Losses for Fast RCNN</a></span></li><li><span><a href=\"#Training-for-Fast-RCNN\" data-toc-modified-id=\"Training-for-Fast-RCNN-5.5.2\"><span class=\"toc-item-num\">5.5.2&nbsp;&nbsp;</span>Training for Fast RCNN</a></span></li></ul></li><li><span><a href=\"#Alternative-learning-startegy-:-we-learned-RPN-network-once-again-but-using-the-initilisation-given-by-Fast-RCNN.\" data-toc-modified-id=\"Alternative-learning-startegy-:-we-learned-RPN-network-once-again-but-using-the-initilisation-given-by-Fast-RCNN.-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>Alternative learning startegy : we learned RPN network once again but using the initilisation given by Fast RCNN.</a></span></li><li><span><a href=\"#Final-architecture\" data-toc-modified-id=\"Final-architecture-5.7\"><span class=\"toc-item-num\">5.7&nbsp;&nbsp;</span>Final architecture</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gZieto6b_7d"
   },
   "source": [
    "This notebook aims to provide functions that produce anchor boxes as decribed in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YTdXFc3b_7e"
   },
   "source": [
    "A box will be describe either as a numpy array $[y^-, x^-, y^+, x^+]$  or as a numpy array $[c_y, c_x, h,w]$\n",
    "\n",
    "TODO : CHECK +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8hRjHO551eS",
    "outputId": "304eb51a-d031-49f9-d969-7cad5183a024"
   },
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tya5x2dU51eU",
    "outputId": "efef5f0a-cfcc-4583-ff80-5521706932a3"
   },
   "outputs": [],
   "source": [
    "!pip3 install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZXgjTh3oAbWt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches #In order to draw the box ! (je sais pas pourquoi j'écris en anglais)\n",
    "from torchvision import models\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import torchvision\n",
    "import pycocotools\n",
    "import copy\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "CUDA_LAUNCH_BLOCKING=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCH = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEMPqMqMrBsn"
   },
   "source": [
    "# Anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.294254Z",
     "start_time": "2021-12-08T23:12:00.281183Z"
    },
    "id": "RtROAiS1b_7f"
   },
   "outputs": [],
   "source": [
    "def vertice_to_yxhw(anchor):\n",
    "    res = (np.mean((anchor[0],anchor[2])),np.mean((anchor[1],anchor[3])), anchor[2] - anchor[0] + 1, anchor[3] - anchor[1]+1)\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QujcnpGi51eW"
   },
   "outputs": [],
   "source": [
    "def vertice_to_yxhw_array(anchor):\n",
    "    res = (np.mean((anchor[:,0],anchor[:,2]), axis = 0),np.mean((anchor[:,1],anchor[:,3]), axis = 0), anchor[:,2] - anchor[:,0] + 1, anchor[:,3] - anchor[:,1]+1)\n",
    "    return np.transpose(np.array(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.310283Z",
     "start_time": "2021-12-08T23:12:00.296255Z"
    },
    "id": "nzn9r1Dzb_7g"
   },
   "outputs": [],
   "source": [
    "def yxhw_to_vertice(anchor):\n",
    "    res = (anchor[0] - anchor[2]/2, anchor[1] - anchor[3]/2, anchor[0] + anchor[2]/2, anchor[1] + anchor[3]/2)\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4DmF9weOH8Uj"
   },
   "outputs": [],
   "source": [
    "#xywh : top left\n",
    "def xywh_to_vertice(anchor):\n",
    "  anchor_perm = (anchor[1] - 0.5*anchor[3] ,anchor[0] + 0.5*anchor[2],anchor[3],anchor[2])\n",
    "  return yxhw_to_vertice(anchor_perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.326279Z",
     "start_time": "2021-12-08T23:12:00.312275Z"
    },
    "id": "4NrJLfwrb_7g"
   },
   "outputs": [],
   "source": [
    "def anchor_box(center, ratio, scale, shape_initial, shape_featured):\n",
    "    sub_width = shape_initial[0]/shape_featured[0]\n",
    "    sub_height = shape_initial[1]/shape_featured[1]\n",
    "    anchor_width = sub_width*scale*np.sqrt(ratio)\n",
    "    anchor_height = sub_height*scale/np.sqrt(ratio)\n",
    "    \n",
    "    ym = center[1] - anchor_height/2\n",
    "    yp = center[1] + anchor_height/2\n",
    "    xm = center[0] - anchor_width/2\n",
    "    xp = center[0] + anchor_width/2\n",
    "    \n",
    "    anchor = (ym,xm,yp,xp)\n",
    "    return(anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.341279Z",
     "start_time": "2021-12-08T23:12:00.328260Z"
    },
    "id": "MEYHa3sPb_7h"
   },
   "outputs": [],
   "source": [
    "def list_centers(shape_initial, shape_featured):\n",
    "    ratio_h = shape_initial[1]/shape_featured[1]\n",
    "    ratio_w = shape_initial[0]/shape_featured[0]\n",
    "    #intiail center is the center at the left top corner\n",
    "    all_centers = [np.array((ratio_w/2, ratio_h/2),dtype=float) + np.array((ratio_w*i, ratio_h*j),dtype=float) for i in range(int(shape_featured[0])) for j in range(int(shape_featured[1]))]\n",
    "    return(all_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.356279Z",
     "start_time": "2021-12-08T23:12:00.343272Z"
    },
    "id": "2klfx8Fjb_7h"
   },
   "outputs": [],
   "source": [
    "def anchor_boxes(list_ratios, list_scales, shape_initial, shape_featured):\n",
    "    list_center = list_centers(shape_initial, shape_featured)\n",
    "    all_anchors = [anchor_box(center, ratio, scale,shape_initial,shape_featured) for center in list_center for ratio in list_ratios\n",
    "                   for scale in list_scales]\n",
    "    return(all_anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.372270Z",
     "start_time": "2021-12-08T23:12:00.358270Z"
    },
    "id": "Y1jD1fLqb_7i"
   },
   "outputs": [],
   "source": [
    "def check_anchor_inside(anchor_box, shape_initial):\n",
    "    ym = anchor_box[0]\n",
    "    yp = anchor_box[2]\n",
    "    xm = anchor_box[1]\n",
    "    xp = anchor_box[3]\n",
    "    is_inside = (min(xm,xp)>0) & (max(xm,xp)<shape_initial[0]) & (max(yp,ym) < shape_initial[1]) & (min(ym,yp) > 0) \n",
    "    return(is_inside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_anchors_vs_gtbox(list_anchors, list_gt_box):\n",
    "  t_anchors = torch.tensor(np.array(list_anchors))\n",
    "  t_list_gt_box = torch.tensor(np.array(list_gt_box))\n",
    "  iou = torchvision.ops.box_iou(t_anchors, t_list_gt_box)\n",
    "  return iou.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTlLHh_Vb_7j"
   },
   "source": [
    "**TODO** : changer la forme de cette fonction en utilisant que des *arrays*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.419270Z",
     "start_time": "2021-12-08T23:12:00.406270Z"
    },
    "id": "B8S6FE2db_7j"
   },
   "outputs": [],
   "source": [
    "#Return an array with :\n",
    "#for all ground truth box, the anchors which maximize the IOU with it\n",
    "#for all anchor, the max of the IOU\n",
    "\n",
    "#the first column of the array is the index and the last the IOU \n",
    "def best_anchors_from_iou(dt_anchors_vs_gtbox):\n",
    "    #index highest by gtbox (cond a)\n",
    "    dt_anchors_vs_gtbox.argmax(axis = 0)\n",
    "    ind_argmax = np.where(dt_anchors_vs_gtbox == dt_anchors_vs_gtbox.max(axis = 0))[0]\n",
    "    cond_a = dt_anchors_vs_gtbox[ind_argmax,:].max(axis = 1)\n",
    "    \n",
    "    #highest by anchors box (cond b)\n",
    "    index = dt_anchors_vs_gtbox.argmax(axis = 1)\n",
    "    iou_max = dt_anchors_vs_gtbox.max(axis = 1)\n",
    "    cond_b = dt_anchors_vs_gtbox[np.arange(dt_anchors_vs_gtbox.shape[0]),index]\n",
    "    \n",
    "    index_res = np.concatenate((ind_argmax,np.arange(dt_anchors_vs_gtbox.shape[0])))\n",
    "    res = np.concatenate((cond_a, cond_b), axis=0)\n",
    "    res = np.column_stack((index_res,res))\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.434260Z",
     "start_time": "2021-12-08T23:12:00.421270Z"
    },
    "id": "9VqTF3Itb_7j"
   },
   "outputs": [],
   "source": [
    "#label_from_iou returns a np.array containing for each anchor its label. (+1 if foreground, 0 if background and -1 if not used\n",
    "#during the learning phase)\n",
    "#The default thresholds are defined according the original paper about Fatest RCNN.\n",
    "\n",
    "def label_from_iou(dt_anchors_vs_gtbox,pos_threshold = 0.7, neg_threshold = 0.3):\n",
    "    label = np.full(dt_anchors_vs_gtbox.shape[0],-1)\n",
    "    iou_max = dt_anchors_vs_gtbox.max(axis = 1)\n",
    "    #positive labels : 1\n",
    "    label[iou_max > pos_threshold] = 1\n",
    "    #negative labels : 0\n",
    "    label[iou_max < neg_threshold] = 0\n",
    "    sum((iou_max < neg_threshold))\n",
    "\n",
    "    #for anchors whose maximize IOU for a given object : +1\n",
    "    dt_anchors_vs_gtbox.argmax(axis = 0)\n",
    "    ind_argmax = np.where(dt_anchors_vs_gtbox == dt_anchors_vs_gtbox.max(axis = 0))[0]\n",
    "    label[ind_argmax] = 1\n",
    "    return(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.449260Z",
     "start_time": "2021-12-08T23:12:00.436260Z"
    },
    "id": "aV_HYx5Ab_7k"
   },
   "outputs": [],
   "source": [
    "def loc(anchor_box, gt_box):\n",
    "    anchor_box = vertice_to_yxhw(anchor_box)\n",
    "    gt_box = vertice_to_yxhw(gt_box)\n",
    "    \n",
    "    y = (gt_box[0] - anchor_box[0])/anchor_box[2]\n",
    "    x = (gt_box[1] - anchor_box[1])/anchor_box[3]\n",
    "    w = np.log(gt_box[3]/anchor_box[3])\n",
    "    h = np.log(gt_box[2]/anchor_box[2])\n",
    "    \n",
    "    return np.array((y,x,h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "E_6_fU8Tb-yM"
   },
   "outputs": [],
   "source": [
    "def loc_list(anchors_list, gt_list):\n",
    "    anchor_box = vertice_to_yxhw_array(np.array(anchors_list))\n",
    "    gt_box = vertice_to_yxhw_array(np.array(gt_list))\n",
    "    \n",
    "    y = (gt_box[:,0] - anchor_box[:,0])/anchor_box[:,2]\n",
    "    x = (gt_box[:,1] - anchor_box[:,1])/anchor_box[:,3]\n",
    "    w = np.log(gt_box[:,3]/anchor_box[:,3])\n",
    "    h = np.log(gt_box[:,2]/anchor_box[:,2])\n",
    "    return np.transpose(np.array((y,x,h,w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.465251Z",
     "start_time": "2021-12-08T23:12:00.451274Z"
    },
    "id": "CI9iedq9b_7k"
   },
   "outputs": [],
   "source": [
    "def deloc(anchor_box, reparam_box):\n",
    "    anchor_box = vertice_to_yxhw(anchor_box)\n",
    "    y = anchor_box[0] + (reparam_box[0] * anchor_box[2])\n",
    "    x = anchor_box[1] + (reparam_box[1] * anchor_box[3])\n",
    "    h = np.exp(reparam_box[2])*anchor_box[2]\n",
    "    w = np.exp(reparam_box[3])*anchor_box[3]\n",
    "    return np.array((y,x,h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "HdCVJYAb51eb"
   },
   "outputs": [],
   "source": [
    "#anchors : vertice\n",
    "#gt_list : prediction\n",
    "def deloc_list(anchors_list, gt_list):\n",
    "    anchor_box = vertice_to_yxhw_array(np.array(anchors_list))\n",
    "    reparam_box = np.array(gt_list)\n",
    "    \n",
    "    y = anchor_box[:,0] + (reparam_box[:,0] * anchor_box[:,2])\n",
    "    x = anchor_box[:,1] + (reparam_box[:,1] * anchor_box[:,3])\n",
    "    h = np.exp(reparam_box[:,2])*anchor_box[:,2]\n",
    "    w = np.exp(reparam_box[:,3])*anchor_box[:,3]\n",
    "    \n",
    "    #    res = (anchor[0] - anchor[2]/2, anchor[1] - anchor[3]/2, anchor[0] + anchor[2]/2, anchor[1] + anchor[3]/2)\n",
    "    #   res = (np.mean((anchor[0],anchor[2])),np.mean((anchor[1],anchor[3])), anchor[2] - anchor[0] + 1, anchor[3] - anchor[1]+1)\n",
    "\n",
    "    return np.transpose(np.array((y - h/2,x-w/2,y + h/2,x + w/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.481256Z",
     "start_time": "2021-12-08T23:12:00.467253Z"
    },
    "id": "jeMfYSLTb_7k"
   },
   "outputs": [],
   "source": [
    "def reparam_all_anchors(list_anchors, list_gt_box,iou,pos_threshold = 0.7, neg_threshold = 0.3):\n",
    "    index_max_gtbox = iou.argmax(axis = 1)\n",
    "    gt_box_by_anchors = [list_gt_box[i] for i in index_max_gtbox]\n",
    "    #TODO : change suboptimal ZIP\n",
    "    res = loc_list(list_anchors, gt_box_by_anchors)\n",
    "    #compute labels\n",
    "    labels = label_from_iou(iou, pos_threshold, neg_threshold)\n",
    "    return list(res),labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.497279Z",
     "start_time": "2021-12-08T23:12:00.483259Z"
    },
    "id": "FSjeRrgIb_7k"
   },
   "outputs": [],
   "source": [
    "def deparam_all_anchors(list_anchors, list_box_param):\n",
    "    res = [(deloc(anchor, box_param)) for anchor,box_param in zip(list_anchors, list_box_param)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.513279Z",
     "start_time": "2021-12-08T23:12:00.500252Z"
    },
    "id": "sORoyapOb_7l"
   },
   "outputs": [],
   "source": [
    "#TODO : heck how to fill when\n",
    "\n",
    "def index_training_proposal(dt_anchors_vs_gtbox, nsize = 256, pos_ratio = 0.5,pos_threshold = 0.7, neg_threshold = 0.3):\n",
    "    #number of positive units we need to reach in the training sample (we want a balanced sample)\n",
    "    nb_pos_to_drawn = round(nsize*pos_ratio)\n",
    "    lab = label_from_iou(dt_anchors_vs_gtbox, pos_threshold, neg_threshold)\n",
    "    pos_lab = np.where(lab == 1)[0]\n",
    "    neg_lab = np.where(lab == 0)[0]\n",
    "    pos = len(pos_lab)\n",
    "    neg = len(neg_lab)\n",
    "    \n",
    "    if (pos > nb_pos_to_drawn):\n",
    "        disabled_index_pos = np.random.choice(pos_lab, size=(pos - nb_pos_to_drawn), replace = False)\n",
    "        lab[disabled_index_pos] = -1\n",
    "    \n",
    "    if (neg > nsize - nb_pos_to_drawn):\n",
    "        if(pos < nb_pos_to_drawn):\n",
    "            disabled_index_neg = np.random.choice(neg_lab, size=(neg - nsize + pos), replace = False)\n",
    "        else:\n",
    "            disabled_index_neg = np.random.choice(neg_lab, size=(neg + nb_pos_to_drawn - nsize), replace = False)\n",
    "        \n",
    "        lab[disabled_index_neg] = -1    \n",
    "    \n",
    "    res = np.where((lab == 0) | (lab == 1))[0]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "WYbv_w7hKfct"
   },
   "outputs": [],
   "source": [
    "# def batch_training_proposal_RPN(image, feature_shape, ratios, scales,gt_box,nsize = 256, pos_ratio = 0.5, pos_threshold = 0.7, neg_threshold = 0.3):\n",
    "#     #define all anchors using the feature map and the initial picture shapes.\n",
    "#     anchors_boxes = anchor_boxes(ratios, scales, tuple(image.shape[2:]), tuple(feature_shape[2:]))\n",
    "#     #check if each box is inside the initial image\n",
    "#     index_boxes_inside = [j for j in range(len(anchors_boxes)) if check_anchor_inside(anchors_boxes[j], image_torch.shape[2:])]\n",
    "#     anchors_boxes = [anchors_boxes[j] for j in index_boxes_inside]\n",
    "#     #IOU anchors vs gt box\n",
    "#     iou_anc_gt_box = iou_anchors_vs_gtbox(anchors_boxes, gt_box)\n",
    "#     #Index of the units we keep\n",
    "#     ind_for_sample = index_training_proposal(iou_anc_gt_box,nsize, pos_ratio)\n",
    "#     anchors_boxes_reparam,lab_anchors = reparam_all_anchors(anchors_boxes,gt_box,iou_anc_gt_box,pos_threshold, neg_threshold)\n",
    "#     return ({\"image\" : image, \"boxes\" : torch.from_numpy(np.array(anchors_boxes_reparam)[ind_for_sample,:]),\n",
    "#              \"labels\" : torch.from_numpy(lab_anchors[ind_for_sample]), \"indices\" : np.array(index_boxes_inside)[ind_for_sample]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.529260Z",
     "start_time": "2021-12-08T23:12:00.515270Z"
    },
    "id": "3VXA4Re5b_7l"
   },
   "outputs": [],
   "source": [
    "#TODO : SUBTOPTIMAL\n",
    "\n",
    "def batch_training_proposal_RPN(image, feature_shape, ratios, scales,gt_box,device, nsize = 256, pos_ratio = 0.5, pos_threshold = 0.7, neg_threshold = 0.3):\n",
    "    #define all anchors using the feature map and the initial picture shapes.\n",
    "    anchors_boxes = anchor_boxes(ratios, scales, tuple(image.shape[2:]), tuple(feature_shape[2:]))\n",
    "    #check if each box is inside the initial image\n",
    "    index_boxes_inside = [j for j in range(len(anchors_boxes)) if check_anchor_inside(anchors_boxes[j], image_torch.shape[2:])]\n",
    "    anchors_boxes_checked = [anchors_boxes[j] for j in index_boxes_inside]\n",
    "    #IOU anchors vs gt box\n",
    "    iou_anc_gt_box = iou_anchors_vs_gtbox(anchors_boxes, gt_box)\n",
    "    iou_anc_gt_box_check = iou_anc_gt_box[index_boxes_inside,:]\n",
    "    #Index of the units we keep\n",
    "    ind_for_sample = index_training_proposal(iou_anc_gt_box_check,nsize, pos_ratio)\n",
    "    indice_to_kept = np.array(index_boxes_inside)[ind_for_sample]\n",
    "\n",
    "    anchors_boxes_reparam,lab_anchors = reparam_all_anchors(anchors_boxes,gt_box,iou_anc_gt_box,pos_threshold, neg_threshold)\n",
    "\n",
    "    final_label = np.full(len(anchors_boxes), -1)\n",
    "    final_label[indice_to_kept] = lab_anchors[indice_to_kept]\n",
    "    \n",
    "    #we need initial anchors_boxes for training FastRNN part\n",
    "    anchors_boxes = torch.from_numpy(np.array(anchors_boxes))\n",
    "    return ({\"image\" : image.to(device), \"boxes\" : torch.from_numpy(np.array(anchors_boxes_reparam)).to(device),\n",
    "             \"labels\" : torch.from_numpy(final_label).to(device), \"anchors_initial\" : anchors_boxes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.559249Z",
     "start_time": "2021-12-08T23:12:00.531283Z"
    },
    "id": "rg80p3vKb_7l"
   },
   "outputs": [],
   "source": [
    "image_torch = 800*torch.rand((1,3,800,800))\n",
    "feature_torch = torch.rand([1,512,50,50])\n",
    "\n",
    "ratio = [0.5, 1, 2]\n",
    "anchor_scales = [8, 16, 32]\n",
    "\n",
    "gt_box = [np.array([20, 30, 400, 500]), np.array([300, 400, 500, 600])]\n",
    "labels_gt_box = np.array((\"chien\",\"chat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "0MkkoKxfDdWx"
   },
   "outputs": [],
   "source": [
    "def batch_training_proposal_multi_RPN(batch,feature_shape, ratio, scales,device,nsize = 256, pos_ratio = 0.5, pos_threshold = 0.7, neg_threshold = 0.3):\n",
    "  image_torch, dict_label = batch\n",
    "  boxes = [list(np.array(dict_label[j][\"boxes\"])) for j in range(len(dict_label))]  #remove empty one\n",
    "  boxes = [[xywh_to_vertice(box) for box in box_list]for box_list in boxes]\n",
    "\n",
    "  gt_labels = [list(np.array(dict_label[j][\"labels\"])) for j in range(len(dict_label))]  #remove empty one\n",
    "  \n",
    "  res = [batch_training_proposal_RPN(image_torch[j].unsqueeze(0), feature_shape, ratio, anchor_scales, boxes[j],device,nsize, pos_ratio, pos_threshold, neg_threshold) for j in range(len(boxes)) if len(boxes[j]) != 0]\n",
    "  \n",
    "  ind_with_box = torch.tensor([i for i in range(len(boxes)) if len(boxes[i]) != 0])\n",
    "  image_torch = torch.index_select(image_torch,0, ind_with_box)\n",
    "  boxes_fin = torch.stack([elem[\"boxes\"] for elem in res])\n",
    "  labels = torch.stack([elem[\"labels\"] for elem in res])\n",
    "  anchors = torch.stack([elem[\"anchors_initial\"] for elem in res])\n",
    "\n",
    "  return {\"images\" : image_torch.to(device), \"boxes\": boxes_fin.to(device), \"labels\": labels.to(device),\"gt_box\": boxes, \"gt_labels\": gt_labels, \"anchors\": anchors}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkGNzP5pb_7m"
   },
   "source": [
    "# Preparation of the proposed region to train the Fast RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:01.750681Z",
     "start_time": "2021-12-08T23:12:01.737311Z"
    },
    "id": "EJeoQrA2b_7m"
   },
   "outputs": [],
   "source": [
    "def clip_predicted_boxes(list_box, th_min, th_max):\n",
    "    list_box = np.array(list_box)\n",
    "    return list(np.clip(list_box,th_min,th_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:01.766679Z",
     "start_time": "2021-12-08T23:12:01.752679Z"
    },
    "id": "sX5nhvlVb_7m"
   },
   "outputs": [],
   "source": [
    "#remove all boxes with at least the width or the height less that 16\n",
    "def boxes_hw_min(list_box, list_score, min_size = 16):\n",
    "    boxes = np.array(list_box)\n",
    "    height = boxes[:, 2] - boxes[:, 0]\n",
    "    width = boxes[:, 3] - boxes[:, 1]\n",
    "    box_kept = np.where((height > min_size) & (width > min_size))[0]\n",
    "    list_box_kept = list(boxes[box_kept])\n",
    "    list_score = [list_score[j] for j in box_kept]\n",
    "    return list_box_kept, list_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:01.782680Z",
     "start_time": "2021-12-08T23:12:01.768698Z"
    },
    "id": "l4n3c2yab_7m"
   },
   "outputs": [],
   "source": [
    "def nms(list_box, list_score, top_pre, top_post, thresold):\n",
    "    list_score = np.array(list_score)\n",
    "    order = list_score.argsort()[::-1]\n",
    "    order = order[:top_pre]\n",
    "    keep = []\n",
    "    list_box = np.array(list_box)\n",
    "    \n",
    "    ym = list_box[:,0]\n",
    "    xm = list_box[:,1]\n",
    "    yp = list_box[:,2]\n",
    "    xp = list_box[:,3]\n",
    "    areas = (xp - xm + 1) * (yp - ym + 1)\n",
    "\n",
    "    while len(order)>0:\n",
    "        i = order[0]\n",
    "        yym = np.maximum(ym[i], ym[order[1:]])\n",
    "        xxm = np.maximum(xm[i], xm[order[1:]])\n",
    "        yyp = np.minimum(yp[i], yp[order[1:]])\n",
    "        xxp = np.minimum(xp[i], xp[order[1:]])\n",
    "        \n",
    "        width = np.maximum(0.0, xxp - xxm + 1)\n",
    "        height = np.maximum(0.0, yyp - yym + 1)\n",
    "        intersection = width*height\n",
    "        ovr = intersection/(areas[i] + areas[order[1:]] - intersection)\n",
    "        \n",
    "        ind_to_keep = np.where(ovr <= thresold)[0]\n",
    "        order = order[ind_to_keep + 1]\n",
    "        keep.append(i)\n",
    "    \n",
    "    keep = keep[:top_post]\n",
    "    return(list_box[keep,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cp5YhD2Qb_7m"
   },
   "source": [
    "# Region proposal network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:44.975470Z",
     "start_time": "2021-12-08T23:12:44.966089Z"
    },
    "id": "9zJP45j1b_7m"
   },
   "outputs": [],
   "source": [
    "#boxes as tensor [N, 5]\n",
    "def roi_pooling(boxes, feature_map,scale,adaptative_max_pool):\n",
    "    boxes_coord = boxes[:,1:].mul(scale).long() #scale + round\n",
    "    res = [feature_map.narrow(0, boxes[i,0].int(),1)[..., boxes_coord[i,1]:(boxes_coord[i,3]+1), boxes_coord[i,0]:(boxes_coord[i,2]+1)] for i in range(boxes_coord.shape[0])]\n",
    "    res = [adaptative_max_pool(element) for element in res]\n",
    "    res = torch.cat(res, axis = 0)\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:53.742770Z",
     "start_time": "2021-12-08T23:12:53.724769Z"
    },
    "id": "kwKmwLDsb_7m"
   },
   "outputs": [],
   "source": [
    "#0 in labels_gt_box must be the background\n",
    "def batch_training_proposal_FastRCNN(feature_map,list_box,list_gt_box,labels_gt_box, nsize = 128, pos_ratio = 0.25, pos_iou_threshold = 0.5,\n",
    "                                    neg_iou_threshold_p = 0.5, neg_iou_threshold_n = 0.0, adaptative_max_pool = torch.nn.AdaptiveMaxPool2d((7,7),return_indices=False),scale = 1):\n",
    "\n",
    "    #number of positive units we need to reach in the training sample (we want a balanced sample)\n",
    "    nb_pos_to_drawn = round(nsize*pos_ratio)\n",
    "    iou = iou_anchors_vs_gtbox(list_box, list_gt_box)\n",
    "    #compute the maximum for each anchor\n",
    "    gt_roi_label = np.argmax(iou, axis = 1)\n",
    "    gt_roi_max = np.max(iou, axis = 1)\n",
    "    labels = labels_gt_box[gt_roi_label]\n",
    "    #assign the label if greater that pos_iou_threshold\n",
    "    #assign background if between the two negative thresholds\n",
    "    gt_pos = np.where((gt_roi_max > pos_iou_threshold))[0]\n",
    "    gt_neg = np.where((gt_roi_max < neg_iou_threshold_p) & (gt_roi_max > neg_iou_threshold_n))[0] #background -- 0\n",
    "\n",
    "    #Nb of positives and negatives boxes get using the thresholds\n",
    "    pos = len(gt_pos)\n",
    "    neg = len(gt_neg)\n",
    "    \n",
    "    enable_index_pos = np.array([],dtype=int)\n",
    "\n",
    "    #Subsampling from it\n",
    "    if (pos > nb_pos_to_drawn):\n",
    "        disabled_index_pos = np.random.choice(range(len(gt_pos)), size=(pos - nb_pos_to_drawn), replace = False)\n",
    "        gt_pos = np.delete(gt_pos, disabled_index_pos)\n",
    "\n",
    "    if (neg > nsize - nb_pos_to_drawn):\n",
    "#         if(pos < nb_pos_to_drawn):\n",
    "#             print(neg)\n",
    "#             print(pos)\n",
    "#             print(nsize)\n",
    "#             disabled_index_neg = np.random.choice(range(len(gt_neg)), size=(neg - nsize + pos), replace = False)\n",
    "#             gt_neg = np.delete(gt_neg, disabled_index_neg)\n",
    "#         else:\n",
    "        disabled_index_neg = np.random.choice(range(len(gt_neg)), size=(neg + nb_pos_to_drawn - nsize), replace = False)\n",
    "        gt_neg = np.delete(gt_neg, disabled_index_neg)\n",
    "\n",
    "    if(neg + pos < nsize):\n",
    "        enable_index_pos = np.random.choice(np.append(gt_pos,gt_neg),size = nsize - neg - pos, replace = True)\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    #if negative : assign background labels with it's 0\n",
    "    labels[gt_neg] = 0\n",
    "    final_index = np.append(np.append(gt_pos,gt_neg),enable_index_pos)\n",
    "    #Non reparams\n",
    "    non_reparam = np.array(list_box)[final_index,:]\n",
    "    #Need to transform from yxhw to xywh\n",
    "    non_reparam = non_reparam[:,(1,0,3,2)]\n",
    "    non_reparam = np.hstack((np.zeros((non_reparam.shape[0],1)), non_reparam))\n",
    "    non_reparam = torch.from_numpy(non_reparam)\n",
    "\n",
    "    data_for_training = roi_pooling(non_reparam, feature_map,scale, adaptative_max_pool)\n",
    "    #Reparams\n",
    "    reparam = [loc(box,gt_box) for box,gt_box in zip(non_reparam, list(np.array(list_gt_box)[gt_roi_label,:]))]\n",
    "    \n",
    "    return  data_for_training, reparam,labels[final_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEAZuBOiX_CF"
   },
   "source": [
    "# Load train dataset \n",
    "\n",
    "J'ai réussi à utiliser l'API Coco via `torchvision.datasets.CocoDetection` (https://pytorch.org/vision/stable/datasets.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "kc-SDR8e-P0z",
    "outputId": "6cc2db42-b751-42d5-ccbb-f5becc4557e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-30 15:22:16--  https://conservancy.umn.edu/bitstream/handle/11299/214865/dataset.zip?sequence=12&isAllowed=y\n",
      "Resolving conservancy.umn.edu (conservancy.umn.edu)... 128.101.122.105\n",
      "Connecting to conservancy.umn.edu (conservancy.umn.edu)|128.101.122.105|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 200\n",
      "Length: 553029970 (527M) [application/zip]\n",
      "Saving to: ‘dataset.zip?sequence=12&isAllowed=y.2’\n",
      "\n",
      "?sequence=12&isAllo  10%[=>                  ]  58.00M  12.8MB/s    eta 43s    ^C\n",
      "Archive:  dataset.zip?sequence=12&isAllowed=y\n",
      "replace dataset/README.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "#Permet d'utiliser la co des serveurs Google (rip la mienne) et assure une meilleure reproductibilité\n",
    "!wget \"https://conservancy.umn.edu/bitstream/handle/11299/214865/dataset.zip?sequence=12&isAllowed=y\"\n",
    "!unzip \"dataset.zip?sequence=12&isAllowed=y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "XuMoQmEAVwfs"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "L6-SecLQN6hP"
   },
   "outputs": [],
   "source": [
    "# The directory containing the source images\n",
    "data_path = \"dataset/instance_version/train\"\n",
    "\n",
    "# The path to the COCO labels JSON file\n",
    "labels_path = \"dataset/instance_version/instances_train_trashcan.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23FFr0UOSPpG"
   },
   "source": [
    "#### Version 4 - resize des images, en ne gardant que les bbox et category_id des targets normalisées, dans un array de dictionnaires (targets de taille variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "oRookaleStv6"
   },
   "outputs": [],
   "source": [
    "#Attention \"bbox\": [x,y,width,height]\n",
    "class CocoDetection_diy_bis(data.Dataset) :\n",
    "    \"\"\"`MS Coco Detection <http://mscoco.org/dataset/#detections-challenge2016>`_ Dataset.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory where images are downloaded to.\n",
    "        annFile (string): Path to json annotation file.\n",
    "        resize : (int,int) size of the images wanted \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, annFile, size, elements_index):\n",
    "        from pycocotools.coco import COCO\n",
    "        self.root = root\n",
    "        self.coco = COCO(annFile)\n",
    "        self.total_ids = list(self.coco.imgs.keys())\n",
    "        self.ids = [self.total_ids[j] for j in elements_index]\n",
    "        self.size = size\n",
    "        self.transform = transforms.Compose([transforms.Resize(size), transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: Tuple (image, target). target is the object returned by ``coco.loadAnns``.\n",
    "        \"\"\"\n",
    "        coco = self.coco\n",
    "        img_id = self.ids[index]\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        target = coco.loadAnns(ann_ids)\n",
    "\n",
    "        path = coco.loadImgs(img_id)[0]['file_name']\n",
    "\n",
    "        # Resize des images :\n",
    "        img = Image.open(os.path.join(self.root, path)).convert('RGB')\n",
    "        original_size = img.size\n",
    "        img = self.transform(img)\n",
    "\n",
    "        # Targets dict :\n",
    "        targets = {'labels':[],'boxes':[]}\n",
    "\n",
    "        for elem in target :  \n",
    "          box = np.copy(elem['bbox'])\n",
    "          box[0] *= self.size[0] / original_size[0]\n",
    "          box[1] *= self.size[1] / original_size[1]\n",
    "          box[2] *= self.size[0] / original_size[0]\n",
    "          box[3] *= self.size[1] / original_size[1]\n",
    "          targets['boxes'].append(box)\n",
    "          targets['labels'].append(elem['category_id'])\n",
    "\n",
    "        return img, targets\n",
    "        \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __repr__(self):\n",
    "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "        tmp = '    Transforms (if any): '\n",
    "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        tmp = '    Target Transforms (if any): '\n",
    "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        return fmt_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "y2652baDVnV8"
   },
   "outputs": [],
   "source": [
    "def collate_fn_diy (batch) : \n",
    "    \"\"\"\n",
    "    Parameters : \n",
    "    -----------\n",
    "    batch : list of tuples (img,targets)\n",
    "\n",
    "    Return : \n",
    "    -------\n",
    "    images : tensor of dim batch_size x 3 x 224 x 224\n",
    "    targets : list of dict containing : \n",
    "        - \"labels\": Tensor of dim [num_target_boxes] (where num_target_boxes is the number of ground-truth objects in the target) containing the class labels\n",
    "        - \"boxes\": Tensor of dim [num_target_boxes, 4] containing the target box coordinates\n",
    "    \"\"\"\n",
    "    imgs, trgts = list(zip(*batch)) # imgs et trgts sont désormais des batch_size-tuples \n",
    "\n",
    "    imgs = [img.unsqueeze(0) for img in list(imgs)] #ajout d'une dimension supplémentaire à tous les tenseurs\n",
    "    images = torch.cat(imgs) # concaténation en un seul tenseur\n",
    "\n",
    "    targets = []\n",
    "    for t in list(trgts) : \n",
    "      targets.append({'labels' : torch.from_numpy(np.array(t[\"labels\"])), \n",
    "                      'boxes' : torch.from_numpy(np.array(t[\"boxes\"]))})\n",
    "    \n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7HBNfbHGA9z"
   },
   "source": [
    "\n",
    "TODO : que faire lorsqu'on a des images sans box et sans label donc ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ah1baurMb_7n"
   },
   "source": [
    "# Training RPN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:13:37.687322Z",
     "start_time": "2021-12-08T23:13:37.348201Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "dd231e88790d42bea6867aa556651c8e",
      "7ff93690eff6496ca0eaff04af2d197e",
      "5d702123da9e48129ff7557a02f72b99",
      "5dfa0e0da40b4ddda4e7dd26a4243622",
      "f77ce4b2ae214c80984ba0b4fa2d2c14",
      "6eefd4e548024038b8e50141bdeef898",
      "079761f87ba8483e9ccf4b97da879ef1",
      "f0bcc1811e5b4fb49be83fd1bf52c557",
      "04e8eac584c947f8a4dd2e7ae9721dd7",
      "e9e980dc151b4fc3a242255c7f92dd34",
      "9ac6009437a84a5d8868dbfa7a209924"
     ]
    },
    "id": "6hNzYE92b_7o",
    "outputId": "86fd9ee3-f3ee-4130-fa6b-c55855a86bc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 200, 200])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "image_torch = 800*torch.rand((1,3,800,800))\n",
    "#We choose the place where we extracted the feature map in order to get H_feature * W_feature around 2400 (papers)\n",
    "resnet50_features = nn.Sequential(*(list(resnet50.children())[:-5]))\n",
    "resnet50_features(image_torch).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pm6g59e7b_7p"
   },
   "source": [
    "https://stackoverflow.com/questions/69480764/what-is-the-difference-between-resnet50-vgg16-etc-and-rcnn-faster-rcnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:13:41.640996Z",
     "start_time": "2021-12-08T23:13:41.621664Z"
    },
    "code_folding": [],
    "id": "EYl81Phib_7p"
   },
   "outputs": [],
   "source": [
    "class RPN(nn.Module):\n",
    "    #TODO : remove embedding_dim using wv.shape[1]\n",
    "    #define all the layers used in model\n",
    "    def __init__(self,mid_channels, in_channels,nb_anchors,pre_trained_model):\n",
    "        \n",
    "        #Constructor\n",
    "        super().__init__()        \n",
    "        \n",
    "        #embedding layer\n",
    "        self.pre_trained_model = pre_trained_model\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, 3, 1, 1)\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv1.bias.data.zero_()\n",
    "        self.sm = nn.Softmax(dim = 2)\n",
    "        self.reg_layer = nn.Conv2d(mid_channels, nb_anchors *4, 1, 1, 0)\n",
    "        self.reg_layer.weight.data.normal_(0, 0.01)\n",
    "        self.reg_layer.bias.data.zero_()\n",
    "\n",
    "        self.cls_layer = nn.Conv2d(mid_channels, nb_anchors *2, 1, 1, 0)\n",
    "        # classification layer\n",
    "        self.cls_layer.weight.data.normal_(0, 0.01)\n",
    "        self.cls_layer.bias.data.zero_()\n",
    "       \n",
    "\n",
    "    def forward(self,img):\n",
    "        nb_images = img.shape[0] #sale ?\n",
    "        x = self.pre_trained_model(img)\n",
    "        x = self.conv1(x)\n",
    "        pred_anchor = self.reg_layer(x)\n",
    "        pred_anchor = pred_anchor.permute(0, 2, 3, 1).contiguous().view(nb_images, -1, 4)\n",
    "        \n",
    "        pred_cls = self.cls_layer(x)\n",
    "        pred_cls = pred_cls.permute(0, 2, 3, 1).contiguous()\n",
    "        pred_cls = pred_cls.view(nb_images, -1, 2)\n",
    "        #pred_cls = self.sm(pred_cls)\n",
    "        return pred_anchor, pred_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "koHem-H00uDv"
   },
   "outputs": [],
   "source": [
    "def l1smooth(pred,target,nb_anchors = 9):\n",
    "  #zeros for those which are negative\n",
    "  boxes = ((target[\"labels\"] == 1).unsqueeze(-1).repeat(1,1,4).float() * target['boxes'])\n",
    "  pred = ((target[\"labels\"] == 1).unsqueeze(-1).repeat(1,1,4).float() * pred[0])\n",
    "  x = torch.abs(boxes.flatten() - pred.flatten())\n",
    "  return sum(0.5*(x**2)*(x < 1) + (x - 0.5)*(x >= 1)) / nb_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "aj4IJlRQ6xGf"
   },
   "outputs": [],
   "source": [
    "def RPN_loss(pred,target,feature_shape, loss_ce = nn.CrossEntropyLoss(ignore_index=-1),loss_sml1 = nn.SmoothL1Loss(reduction = \"sum\"),  lamb = 10):\n",
    "  #Remove all -1 for the computation of the CE loss\n",
    "  #Classification part\n",
    "  loss_cls = loss_ce(pred[1].view(-1,2),target['labels'].view(-1,1).squeeze().long())\n",
    "  #Regression part\n",
    "  boxes = ((target[\"labels\"] == 1).unsqueeze(-1).repeat(1,1,4).float() * target['boxes'])\n",
    "  pred = ((target[\"labels\"] == 1).unsqueeze(-1).repeat(1,1,4).float() * pred[0])\n",
    "  loss_reg = loss_sml1(boxes, pred)/torch.prod(feature_shape[2:])\n",
    "  #Final loss\n",
    "  loss = loss_cls + lamb*loss_reg\n",
    "  return loss\n",
    "\n",
    "def RPN_loss2(pred,target, nb_anchors = 56*56, lamb = 10):\n",
    "  #Remove all -1 for the computation of the CE loss\n",
    "  #Classification part\n",
    "  loss_ce = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "  loss_cls = loss_ce(pred[1].view(-1,2),target['labels'].view(-1,1).squeeze().long())\n",
    "  #Regression part\n",
    "  loss_reg = l1smooth(pred, target, nb_anchors)\n",
    "  #Final loss\n",
    "  loss = loss_cls + lamb*loss_reg\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3po-CtKr4v7"
   },
   "source": [
    "The new version of RPN is at least 8 time faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Qnn6nE28UI3"
   },
   "source": [
    "As indicated in the paper, we are using SGD optimiser with 0.001 as learning rate and 0.9 for momemtum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "SananpqIs0XB"
   },
   "outputs": [],
   "source": [
    "def fn_train_step_RPN(model, loss_fn, optimizer,feature_shape = torch.tensor((1,1,56,56))):\n",
    "  def train_step(data_loader):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    for input in data_loader:\n",
    "      input = batch_training_proposal_multi_RPN(input, feature_shape, ratio, anchor_scales, device)\n",
    "      output = model_RPN(input[\"images\"])\n",
    "\n",
    "      loss = RPN_loss(output, input,feature_shape)\n",
    "      loss.backward()\n",
    "\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      losses =+ loss.item()\n",
    "\n",
    "    return losses/len(data_loader)\n",
    "\n",
    "  return train_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sHG3LKTZvitA"
   },
   "source": [
    "## Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wNd1lcYOudBZ",
    "outputId": "ecc46dea-efd5-4828-8575-1facc549678c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.29s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.34s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "prop_train = 0.5\n",
    "prop_valid = 0.3\n",
    "prop_test = 0.2\n",
    "\n",
    "n = 6000\n",
    "n_train = int(n*prop_train)\n",
    "n_test = int(n*prop_test)\n",
    "n_valid = n - n_train- n_test\n",
    "\n",
    "ind_n_train = np.random.choice(np.arange(n), n_train)\n",
    "ind_n_test = np.random.choice(np.setdiff1d(np.arange(n), ind_n_train), n_test)\n",
    "ind_n_valid = np.setdiff1d(np.setdiff1d(np.arange(n), ind_n_train),ind_n_test)\n",
    "\n",
    "#train Dataloader\n",
    "instances_train = CocoDetection_diy_bis(root = data_path, annFile = labels_path, size=(224,224), elements_index = ind_n_train)\n",
    "instances_train_dataloader = DataLoader(instances_train, batch_size=1, shuffle=True, collate_fn = collate_fn_diy)\n",
    "\n",
    "#valid dataloader\n",
    "instances_valid = CocoDetection_diy_bis(root = data_path, annFile = labels_path, size=(224,224), elements_index = ind_n_valid)\n",
    "instances_valid_dataloader = DataLoader(instances_valid, batch_size=1, shuffle=True, collate_fn = collate_fn_diy)\n",
    "\n",
    "\n",
    "#test dataloader\n",
    "instances_test = CocoDetection_diy_bis(root = data_path, annFile = labels_path, size=(224,224), elements_index = ind_n_test)\n",
    "instances_test_dataloader = DataLoader(instances_test, batch_size=1, shuffle=True, collate_fn = collate_fn_diy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "TSnXqSR-8TU6"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "feature_shape = (1,1,56,56)\n",
    "model_RPN = RPN(256,256,9,resnet50_features).to(device)\n",
    "optimizer = optim.SGD(model_RPN.parameters(), lr=0.001, momentum=0.9)\n",
    "best_model = RPN(256,256,9,resnet50_features).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o4_bCnb8CFZl",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "0b2efcdf-d827-4c44-a93d-3a4feb4d2ce9"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "#TODO : save better model ! on valid ?\n",
    "t0 = time.time()\n",
    "loss_list_train = [float('inf')]\n",
    "loss_list_valid = [float('inf')]\n",
    "nb_epoch = N_EPOCH\n",
    "i = 0\n",
    "\n",
    "\n",
    "for epoch in range(nb_epoch):\n",
    "  #training\n",
    "  model_RPN.train()\n",
    "  losses = 0\n",
    "  for element in instances_train_dataloader:\n",
    "        if(len(element[1][0][\"labels\"]) != 0):\n",
    "            input = batch_training_proposal_multi_RPN(element, feature_shape, ratio, anchor_scales, device)\n",
    "            output = model_RPN(input[\"images\"])\n",
    "            loss = RPN_loss(output, input,torch.tensor(feature_shape))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            losses =+ loss.item()\n",
    "  loss_epch = losses/len(instances_train_dataloader)\n",
    "  loss_list_train.append(loss_epch)\n",
    "  #valid\n",
    "  with torch.no_grad():\n",
    "    losses = 0\n",
    "    for element in instances_valid_dataloader:\n",
    "        if(len(element[1][0][\"labels\"]) != 0):\n",
    "          input = batch_training_proposal_multi_RPN(element, feature_shape, ratio, anchor_scales, device)\n",
    "          output = model_RPN(input[\"images\"])\n",
    "          model_RPN.eval()\n",
    "          loss = RPN_loss(output, input, torch.tensor(feature_shape))\n",
    "          losses =+ loss.item()\n",
    "    loss_epch_valid = losses/len(instances_valid_dataloader)\n",
    "    if loss_epch_valid < min(loss_list_valid):\n",
    "        best_model = (copy.deepcopy(model_RPN.state_dict()))\n",
    "        #Ajoutez des métriques\n",
    "    loss_list_valid.append(loss_epch_valid)\n",
    "    print(f'\\tEpoch {i} : Train Loss: {loss_epch:.3f} | \\tValid Loss: {loss_epch_valid:.3f}')\n",
    "  i += 1\n",
    " \n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFuXwXYi51eh"
   },
   "outputs": [],
   "source": [
    "torch.save(best_model, \"model_RPN.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load previous trained Fast model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RPN = RPN(256,256,9,resnet50_features).to(device)\n",
    "model_RPN.load_state_dict(torch.load(\"model_RPN.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2hA9uAT51eh"
   },
   "outputs": [],
   "source": [
    "exemple = next(iter(instances_train_dataloader))\n",
    "exemple = batch_training_proposal_multi_RPN(exemple, feature_shape, ratio, anchor_scales, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ovv1JwXg51eh"
   },
   "outputs": [],
   "source": [
    "exemple[\"gt_box\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w6kJvdpm51eh"
   },
   "outputs": [],
   "source": [
    "model_RPN(exemple[\"images\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible d'utiliser directement le tensor image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kVHAhCJ51ei"
   },
   "source": [
    "## Transition between RPN and FastRCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=cSO1nUj495Y&ab_channel=ArdianUmam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_exemple = next(iter(instances_train_dataloader))\n",
    "exemple =  batch_training_proposal_multi_RPN(batch_exemple, feature_shape, ratio, anchor_scales, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0IihDfwk51ei"
   },
   "outputs": [],
   "source": [
    "pre_trained_model_after_RPN = model_RPN._modules[\"pre_trained_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0 in labels_gt_box must be the background\n",
    "def batch_training_proposal_FastRCNN(feature_map,list_box,list_gt_box,labels_gt_box,device, nsize = 128, pos_ratio = 0.25, pos_iou_threshold = 0.5,\n",
    "                                    neg_iou_threshold_p = 0.5, neg_iou_threshold_n = 0.0, adaptative_max_pool = torch.nn.AdaptiveMaxPool2d((7,7),return_indices=False),\n",
    "                                     scale = 1):\n",
    "\n",
    "    #number of positive units we need to reach in the training sample (we want a balanced sample)\n",
    "    nb_pos_to_drawn = round(nsize*pos_ratio)\n",
    "    iou = iou_anchors_vs_gtbox(list_box, list_gt_box)\n",
    "    #compute the maximum for each anchor\n",
    "    gt_roi_label = np.argmax(iou, axis = 1)\n",
    "    gt_roi_max = np.max(iou, axis = 1)\n",
    "    labels = labels_gt_box[gt_roi_label]\n",
    "    #assign the label if greater that pos_iou_threshold\n",
    "    #assign background if between the two negative thresholds\n",
    "    gt_pos = np.where((gt_roi_max > pos_iou_threshold))[0]\n",
    "    gt_neg = np.where((gt_roi_max < neg_iou_threshold_p) & (gt_roi_max > neg_iou_threshold_n))[0] #background -- 0\n",
    "\n",
    "    #Nb of positives and negatives boxes get using the thresholds\n",
    "    pos = len(gt_pos)\n",
    "    neg = len(gt_neg)\n",
    "    \n",
    "    enable_index_pos = np.array([],dtype=int)\n",
    "    \n",
    "    #Subsampling from it\n",
    "    if (pos > nb_pos_to_drawn):\n",
    "        disabled_index_pos = np.random.choice(range(len(gt_pos)), size=(pos - nb_pos_to_drawn), replace = False)\n",
    "        gt_pos = np.delete(gt_pos, disabled_index_pos)\n",
    "\n",
    "    if (neg > nsize - nb_pos_to_drawn):\n",
    "        disabled_index_neg = np.random.choice(range(len(gt_neg)), size=(neg + nb_pos_to_drawn - nsize), replace = False)\n",
    "        gt_neg = np.delete(gt_neg, disabled_index_neg)\n",
    "\n",
    "    if(len(gt_neg) + len(gt_pos) < nsize):\n",
    "        enable_index_pos = np.random.choice(np.append(gt_pos,gt_neg),size = nsize - (len(gt_neg) + len(gt_pos)), replace = True)\n",
    "        \n",
    "    #if negative : assign background labels with it's 1000\n",
    "    labels[gt_neg] = 1000\n",
    "    labels[np.where(labels != 1000)] = 412 #imagenet for trashes\n",
    "    final_index = np.append(np.append(gt_pos,gt_neg),enable_index_pos)\n",
    "    #Non reparams\n",
    "    non_reparam = np.array(list_box)[final_index,:]\n",
    "    #Need to transform from yxhw to xywh\n",
    "    non_reparam_xywh = non_reparam[:,(1,0,3,2)]\n",
    "    non_reparam_xywh = np.hstack((np.zeros((non_reparam_xywh.shape[0],1)), non_reparam_xywh))\n",
    "    non_reparam_torch = torch.from_numpy(non_reparam_xywh)\n",
    "    \n",
    "\n",
    "    data_for_training = roi_pooling(non_reparam_torch, feature_map,scale, adaptative_max_pool)\n",
    "    array_gt_box_for_each = np.array(list_gt_box)[gt_roi_label,:]\n",
    "    reparam = loc_list(non_reparam, array_gt_box_for_each[final_index,:])\n",
    "    return  {'feature_map_extract' : data_for_training.to(device), 'boxes' : torch.tensor(np.array(reparam)).to(device), \n",
    "             'labels' : torch.tensor(np.array(labels[final_index])).to(device), 'non_reparam_box' : torch.from_numpy(non_reparam).to(device)}\n",
    "#data for training : set of extracted part of feature maps using roi pooling\n",
    "#boxes\n",
    "#labels for each boxes : ATTENTION PASSE EN IMAGENET !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_c_Tqns51ei"
   },
   "outputs": [],
   "source": [
    "#exemple batch containing a single exemple\n",
    "sm = nn.Softmax(dim = 2)\n",
    "def RPN_to_FRCNN(exemple, feature_size, min_size_anchors, before_top_nms,after_top_nms,pos_t, model, feature_map):\n",
    "    #no learning in this part !\n",
    "    with torch.no_grad():\n",
    "        res = model(exemple[\"images\"])\n",
    "    \n",
    "    prob = sm(res[0])[0,:,1].detach().cpu().numpy()\n",
    "    anchors = list(np.array(exemple[\"anchors\"][0].cpu()))\n",
    "    list_box = list((res[0][0].detach().cpu()).numpy())\n",
    "    boxes_hw = boxes_hw_min(clip_predicted_boxes(deloc_list(anchors,list_box),0,feature_size),prob,min_size_anchors)\n",
    "    list_box = list(nms(boxes_hw[0], boxes_hw[1], before_top_nms,after_top_nms,pos_t))\n",
    "    return {\"feature_map\" : feature_map, \"list_roi\" : list_box, \"list_gt_labels\" : np.array(exemple[\"gt_labels\"][0]), \"list_gt_box\" : list(exemple[\"gt_box\"][0])}\n",
    "\n",
    "after_rpn = RPN_to_FRCNN(exemple, 224,16,12000,1000,0.7,model_RPN, pre_trained_model_after_RPN(exemple[\"images\"]))\n",
    "\n",
    "res = batch_training_proposal_FastRCNN(after_rpn[\"feature_map\"],after_rpn[\"list_roi\"],after_rpn[\"list_gt_box\"],after_rpn[\"list_gt_labels\"],device,\n",
    "                                       nsize = 128, pos_ratio = 0.25, pos_iou_threshold = 0.5,\n",
    "                                adaptative_max_pool = torch.nn.AdaptiveMaxPool2d((7,7),return_indices=False), scale = 1/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fast_RCNN(nn.Module):\n",
    "    #TODO : remove embedding_dim using wv.shape[1]\n",
    "    #define all the layers used in model\n",
    "    def __init__(self,in_channels,mid_channels,nb_classes,pre_trained_model,min_size_anchors,\n",
    "                 before_top_nms,after_top_nms,pos_t, model_RPN, nsize, \n",
    "                 pos_ratio, pos_iou_threshold, number_roi_pooling, scale):\n",
    "        \n",
    "        #Constructor\n",
    "        super().__init__()        \n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.mid_channels = mid_channels\n",
    "        self.nb_classes = nb_classes\n",
    "        self.pre_trained_model = pre_trained_model\n",
    "        self.min_size_anchors = min_size_anchors\n",
    "        self.before_top_nms = before_top_nms\n",
    "        self.after_top_nms = after_top_nms\n",
    "        self.pos_t = pos_t\n",
    "        self.model_RPN = model_RPN\n",
    "        \n",
    "        #for batch FRCNN\n",
    "        self.nsize = nsize\n",
    "        self.pos_ratio = pos_ratio\n",
    "        self.pos_iou_threshold = pos_iou_threshold\n",
    "        self.number_roi_pooling = number_roi_pooling\n",
    "        self.scale = scale\n",
    "        \n",
    "        #embedding layer\n",
    "        self.pre_trained_model = pre_trained_model\n",
    "        self.lin1 = nn.Linear(in_channels, mid_channels)\n",
    "        self.lin2 = nn.Linear(mid_channels, mid_channels)\n",
    "        self.score = nn.Linear(mid_channels, (nb_classes + 1))\n",
    "        self.boxes = nn.Linear(mid_channels, 4*(nb_classes + 1))\n",
    "        \n",
    "        self.boxes.weight.data.normal_(0, 0.01)\n",
    "        self.boxes.bias.data.zero_()\n",
    "\n",
    "        self.score.weight.data.normal_(0, 0.01)\n",
    "        self.score.bias.data.zero_()\n",
    "       \n",
    "    \n",
    "        \n",
    "    def forward(self,batch):\n",
    "        nb_images = batch[\"images\"].shape[0] #sale ?\n",
    "        feature_maped = self.pre_trained_model(batch[\"images\"].to(device))\n",
    "        after_rpn = RPN_to_FRCNN(batch,batch[\"images\"].shape[-1],self.min_size_anchors,self.before_top_nms,self.after_top_nms,self.pos_t,self.model_RPN, feature_maped)\n",
    "        minibatch_FRCNN = batch_training_proposal_FastRCNN(after_rpn[\"feature_map\"],after_rpn[\"list_roi\"],after_rpn[\"list_gt_box\"],after_rpn[\"list_gt_labels\"], \n",
    "                                                           device,nsize = self.nsize, pos_ratio = self.pos_ratio, pos_iou_threshold = self.pos_iou_threshold,\n",
    "                                adaptative_max_pool = torch.nn.AdaptiveMaxPool2d((self.number_roi_pooling,self.number_roi_pooling),return_indices=False),\n",
    "                                                           scale = self.scale)\n",
    "        x = minibatch_FRCNN[\"feature_map_extract\"] #put the feature map extracted\n",
    "        x = x.view(128, -1) #128 as parameters\n",
    "        x = self.lin1(x)\n",
    "        x = self.lin2(x)\n",
    "        x_score = self.score(x)\n",
    "        x_boxes = self.boxes(x)\n",
    "        return x_boxes,x_score, minibatch_FRCNN\n",
    "\n",
    "#def RPN_to_FRCNN(exemple, feature_size, min_size_anchors, before_top_nms,after_top_nms,pos_t, model, feature_map):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "image_torch = 800*torch.rand((1,3,800,800))\n",
    "#We choose the place where we extracted the feature map in order to get H_feature * W_feature around 2400 (papers)\n",
    "resnet50_features = nn.Sequential(*(list(resnet50.children())[:-5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_rcnn = Fast_RCNN(12544, 4096, 1000, resnet50_features,16,12000,1000,0.7,model_RPN,128,0.25,0.5,7,1/4).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses for Fast RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target : results of batch_training_proposal_FastRCNN function (dict with featured_extracted, boxes, labels)\n",
    "#pred : resultats of forward function\n",
    "\n",
    "def FRCNN_loss(pred,target, loss_ce = nn.CrossEntropyLoss(ignore_index=-1),loss_sml1 = nn.SmoothL1Loss(reduction = \"sum\"),  lamb = 1):\n",
    "  #Remove all -1 for the computation of the CE loss\n",
    "  #Classification part\n",
    "  loss_cls = loss_ce(pred[1],target[\"labels\"])\n",
    "  #Regression part (\"1000\" is the background)\n",
    "  boxes = (res[\"labels\"] != 1000).unsqueeze(-1).repeat(1,1,4).float() * res[\"boxes\"]\n",
    "  nb_feature = pred[0].shape[0]\n",
    "  pred = pred[0].view(nb_feature,-1,4)[torch.arange(0,nb_feature).long(), res[\"labels\"]] * (res[\"labels\"] != 1000).unsqueeze(-1).repeat(1,1,4).float() \n",
    "  loss_reg = loss_sml1(boxes, pred)\n",
    "  #Final loss\n",
    "  loss = loss_cls + lamb*loss_reg\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training for Fast RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)\n",
    "resnet50_features = nn.Sequential(*(list(resnet50.children())[:-5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "fast_rcnn = Fast_RCNN(12544, 4096, 1000, copy.deepcopy(resnet50_features),16,12000,1000,0.7,model_RPN,128,0.25,0.5,7,1/4).to(device)\n",
    "optimizer = optim.SGD(fast_rcnn.parameters(), lr=0.001, momentum=0.9)\n",
    "best_model_frcnn = Fast_RCNN(12544, 4096, 1000, copy.deepcopy(resnet50_features),16,12000,1000,0.7,model_RPN,128,0.25,0.5,7,1/4).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#TODO : save better model ! on valid ?\n",
    "t0 = time.time()\n",
    "loss_list_train = [float('inf')]\n",
    "loss_list_valid = [float('inf')]\n",
    "nb_epoch = N_EPOCH\n",
    "i = 0\n",
    "\n",
    "\n",
    "for epoch in range(nb_epoch):\n",
    "  #training\n",
    "  fast_rcnn.train()\n",
    "  losses = 0\n",
    "  for element in instances_train_dataloader:\n",
    "    if(len(element[1][0][\"labels\"]) != 0):\n",
    "        exemple =  batch_training_proposal_multi_RPN(batch_exemple, feature_shape, ratio, anchor_scales, device)    \n",
    "        output = fast_rcnn(exemple)\n",
    "        loss = FRCNN_loss(output, output[2])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses =+ loss.item()\n",
    "  loss_epch = losses/len(instances_train_dataloader)\n",
    "  loss_list_train.append(loss_epch)\n",
    "  #valid\n",
    "  with torch.no_grad():\n",
    "    losses = 0\n",
    "    for element in instances_valid_dataloader:\n",
    "        if(len(element[1][0][\"labels\"]) != 0):\n",
    "          input = batch_training_proposal_multi_RPN(element, feature_shape, ratio, anchor_scales, device)\n",
    "          output = fast_rcnn(exemple)\n",
    "          fast_rcnn.eval()\n",
    "          loss = FRCNN_loss(output, output[2])\n",
    "          losses =+ loss.item()\n",
    "    loss_epch_valid = losses/len(instances_valid_dataloader)\n",
    "    if loss_epch_valid < min(loss_list_valid):\n",
    "        print(True)\n",
    "        best_model_frcnn = copy.deepcopy(fast_rcnn.state_dict())\n",
    "        #Ajoutez des métriques\n",
    "    loss_list_valid.append(loss_epch_valid)\n",
    "    print(f'\\tEpoch {i} : Train Loss: {loss_epch:.3f} | \\tValid Loss: {loss_epch_valid:.3f}')\n",
    "  i += 1\n",
    "\n",
    "t1 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model_frcnn,\"model_frcnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative learning startegy : we learned RPN network once again but using the initilisation given by Fast RCNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_rcnn.load_state_dict(torch.load(\"model_frcnn.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_after_FRCNN = copy.deepcopy(fast_rcnn.pre_trained_model)\n",
    "feature_shape = (1,1,56,56)\n",
    "\n",
    "model_RPN_after_FRCNN = RPN(256,256,9,feature_extractor_after_FRCNN).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze pre-trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_RPN_after_FRCNN.pre_trained_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model_RPN_after_FRCNN.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#TODO : save better model ! on valid ?\n",
    "t0 = time.time()\n",
    "loss_list_train = [float('inf')]\n",
    "loss_list_valid = [float('inf')]\n",
    "nb_epoch = N_EPOCH\n",
    "i = 0\n",
    "\n",
    "best_model_afterFRCNN = RPN(256,256,9,feature_extractor_after_FRCNN).to(device)\n",
    "\n",
    "for epoch in range(nb_epoch):\n",
    "  #training\n",
    "  model_RPN_after_FRCNN.train()\n",
    "  losses = 0\n",
    "  for element in instances_train_dataloader:\n",
    "        if(len(element[1][0][\"labels\"]) != 0):\n",
    "            input = batch_training_proposal_multi_RPN(element, feature_shape, ratio, anchor_scales, device)\n",
    "            output = model_RPN_after_FRCNN(input[\"images\"])\n",
    "            loss = RPN_loss(output, input,torch.tensor(feature_shape))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            losses =+ loss.item()\n",
    "  loss_epch = losses/len(instances_train_dataloader)\n",
    "  loss_list_train.append(loss_epch)\n",
    "  #valid\n",
    "  with torch.no_grad():\n",
    "    losses = 0\n",
    "    for element in instances_valid_dataloader:\n",
    "        if(len(element[1][0][\"labels\"]) != 0):\n",
    "          input = batch_training_proposal_multi_RPN(element, feature_shape, ratio, anchor_scales, device)\n",
    "          output = model_RPN_after_FRCNN(input[\"images\"])\n",
    "          model_RPN_after_FRCNN.eval()\n",
    "          loss = RPN_loss(output, input, torch.tensor(feature_shape))\n",
    "          losses =+ loss.item()\n",
    "    loss_epch_valid = losses/len(instances_valid_dataloader)\n",
    "    if loss_epch_valid < min(loss_list_valid):\n",
    "        best_model_afterFRCNN = (copy.deepcopy(model_RPN.state_dict()))\n",
    "        #Ajoutez des métriques\n",
    "    loss_list_valid.append(loss_epch_valid)\n",
    "    print(f'\\tEpoch {i} : Train Loss: {loss_epch:.3f} | \\tValid Loss: {loss_epch_valid:.3f}')\n",
    "  i += 1\n",
    " \n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model_afterFRCNN, \"RPN_after_FRCNN.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RPN_after_FRCNN.load_state_dict(torch.load(\"RPN_after_FRCNN.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "fast_rcnn_after_alter = Fast_RCNN(12544, 4096, 1000, copy.deepcopy(model_RPN_after_FRCNN.pre_trained_model),16,12000,1000,0.7,\n",
    "                                  copy.deepcopy(model_RPN_after_FRCNN),128,0.25,0.5,7,1/4).to(device)\n",
    "best_model_frcnn_after_alter = Fast_RCNN(12544, 4096, 1000, copy.deepcopy(model_RPN_after_FRCNN.pre_trained_model),16,12000,1000,0.7,\n",
    "                                  copy.deepcopy(model_RPN_after_FRCNN),128,0.25,0.5,7,1/4).to(device)\n",
    "optimizer = optim.SGD(fast_rcnn_after_alter.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in fast_rcnn_after_alter.pre_trained_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#TODO : save better model ! on valid ?\n",
    "t0 = time.time()\n",
    "loss_list_train = [float('inf')]\n",
    "loss_list_valid = [float('inf')]\n",
    "nb_epoch = N_EPOCH\n",
    "i = 0\n",
    "\n",
    "for epoch in range(nb_epoch):\n",
    "  #training\n",
    "  fast_rcnn_after_alter.train()\n",
    "  losses = 0\n",
    "  for element in instances_train_dataloader:\n",
    "    exemple =  batch_training_proposal_multi_RPN(batch_exemple, feature_shape, ratio, anchor_scales, device)    \n",
    "    output = fast_rcnn_after_alter(exemple)\n",
    "    loss = FRCNN_loss(output, output[2])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    losses =+ loss.item()\n",
    "  loss_epch = losses/len(instances_train_dataloader)\n",
    "  loss_list_train.append(loss_epch)\n",
    "  #valid\n",
    "  with torch.no_grad():\n",
    "    losses = 0\n",
    "    for element in instances_valid_dataloader:\n",
    "        if(len(element[1][0][\"labels\"]) != 0):\n",
    "          input = batch_training_proposal_multi_RPN(element, feature_shape, ratio, anchor_scales, device)\n",
    "          output = fast_rcnn_after_alter(exemple)\n",
    "          fast_rcnn_after_alter.eval()\n",
    "          loss = FRCNN_loss(output, output[2])\n",
    "          losses =+ loss.item()\n",
    "    loss_epch_valid = losses/len(instances_valid_dataloader)\n",
    "    if loss_epch_valid < min(loss_list_valid):\n",
    "        best_model_frcnn_after_alter = copy.deepcopy(fast_rcnn_after_alter.state_dict())\n",
    "        #Ajoutez des métriques\n",
    "    loss_list_valid.append(loss_epch_valid)\n",
    "    print(f'\\tEpoch {i} : Train Loss: {loss_epch:.3f} | \\tValid Loss: {loss_epch_valid:.3f}')\n",
    "  i += 1\n",
    "\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model_frcnn_after_alter, \"final_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RPN_after = RPN(256,256,9,copy.deepcopy(resnet50_features)).to(device)\n",
    "\n",
    "model_RPN_after.load_state_dict(torch.load(\"RPN_after_FRCNN.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_rcnn = Fast_RCNN(12544, 4096, 1000, copy.deepcopy(model_RPN_after.pre_trained_model),16,12000,1000,0.7,\n",
    "                      model_RPN_after,128,0.25,0.5,7,1/4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_rcnn.load_state_dict(torch.load(\"final_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "batch_exemple = next(iter(instances_train_dataloader))\n",
    "exemple =  batch_training_proposal_multi_RPN(batch_exemple, feature_shape, ratio, anchor_scales, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_rpn = RPN_to_FRCNN(exemple, 224,16,12000,1000,0.7,model_RPN, model_RPN_after.pre_trained_model(exemple[\"images\"]))\n",
    "\n",
    "res = batch_training_proposal_FastRCNN(after_rpn[\"feature_map\"],after_rpn[\"list_roi\"],after_rpn[\"list_gt_box\"],after_rpn[\"list_gt_labels\"],device,\n",
    "                                       nsize = 128, pos_ratio = 0.25, pos_iou_threshold = 0.5,\n",
    "                                adaptative_max_pool = torch.nn.AdaptiveMaxPool2d((7,7),return_indices=False), scale = 1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_to_pict_and_boxes(exemple, model, iou_min = 0.2,\n",
    "                                invTrans = transforms.Normalize(\n",
    "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255],\n",
    "    std=[1/0.229, 1/0.224, 1/0.255]\n",
    ")):\n",
    "    pred = model(exemple)\n",
    "\n",
    "    tables = [table.squeeze().detach().cpu().numpy() for table in pred[0].view(128,-1,4).split(1,1)]\n",
    "\n",
    "    res_deparam = deloc_list(np.repeat(pred[2][\"non_reparam_box\"].detach().cpu().numpy(),1001,axis = 1),\n",
    "                            np.hstack(tables))\n",
    "\n",
    "    res_deparam = res_deparam.clip(0, 255)\n",
    "    \n",
    "    sm1 = nn.Softmax(dim = 1)\n",
    "    proba = sm1(model(exemple)[1])\n",
    "\n",
    "    score = proba[:,411]\n",
    "    ind = torchvision.ops.batched_nms(torch.from_numpy(res_deparam).to(device), score, torch.zeros(res_deparam.shape[0]).to(device),\n",
    "                                      iou_min)\n",
    "\n",
    "    box_to_keep = res_deparam[ind.cpu().numpy(),:]\n",
    "\n",
    "    box_to_keep = box_to_keep.clip(0,255)\n",
    "    box = box_to_keep[:, (1,0,3,2)]\n",
    "    \n",
    "    return {\"images\" : invTrans(exemple[\"images\"]), \"boxes\" : box}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pictures_and_boxes(image_tensor, boxes):\n",
    "    img = transforms.functional.to_pil_image(image_tensor.squeeze())\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for box in boxes.tolist():\n",
    "        draw.rectangle(xy = box)\n",
    "    #Add grown trunth :\n",
    "    gt_box = [box[[1,0,3,2]] for box in exemple[\"gt_box\"][0]]  \n",
    "    print(box)\n",
    "    for gtb in gt_box:\n",
    "        draw.rectangle(xy = gtb.tolist(), outline = \"red\")\n",
    "    return(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4666666666666667\n",
      "[0.0, 0.0, 0.2689736932516098, 0.4433048591017723]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=224x224 at 0x7FA695E00EF0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_exemple = next(iter(instances_train_dataloader))\n",
    "exemple =  batch_training_proposal_multi_RPN(batch_exemple, feature_shape, ratio, anchor_scales, device)\n",
    "res = prediction_to_pict_and_boxes(exemple, fast_rcnn)\n",
    "pictures_and_boxes(res[\"images\"],res[\"boxes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4666666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          ...,\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.0665, -2.0665, -2.0665,  ..., -2.0665, -2.0665, -2.0665],\n",
       "          [-1.9980, -1.9980, -1.9980,  ..., -1.9980, -1.9980, -1.9980]],\n",
       " \n",
       "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          ...,\n",
       "          [-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0182, -2.0182],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
       " \n",
       "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          ...,\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]),\n",
       " {'labels': [17],\n",
       "  'boxes': [[3.0747244449389224e-15,\n",
       "    8.517149424017632e-09,\n",
       "    6.627979491057066e-15,\n",
       "    4.025494475142269e-09]]})"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(instances_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.26s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "instances_train2 = CocoDetection_diy_bis(root = data_path, annFile = labels_path, size=(224,224), elements_index = ind_n_train)\n",
    "instances_train_dataloader2 = DataLoader(instances_train2, batch_size=1, shuffle=False, collate_fn = collate_fn_diy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         ...,\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.0665, -2.0665, -2.0665,  ..., -2.0665, -2.0665, -2.0665],\n",
      "         [-1.9980, -1.9980, -1.9980,  ..., -1.9980, -1.9980, -1.9980]],\n",
      "\n",
      "        [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         ...,\n",
      "         [-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0182, -2.0182],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "        [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         ...,\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]), {'labels': [17], 'boxes': [array([ 50.87142857, 106.40545809, 109.66016347,  50.29083821])]})\n",
      "(tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.0665, -2.0665, -2.0665,  ..., -2.0665, -2.0665, -2.0665],\n",
      "          [-1.9980, -1.9980, -1.9980,  ..., -1.9980, -1.9980, -1.9980]],\n",
      "\n",
      "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          ...,\n",
      "          [-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0182, -2.0182],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]]), [{'labels': tensor([17]), 'boxes': tensor([[ 50.8714, 106.4055, 109.6602,  50.2908]], dtype=torch.float64)}])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(instances_train2)))\n",
    "print(next(iter(instances_train_dataloader2)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "anchor_boxes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04e8eac584c947f8a4dd2e7ae9721dd7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "079761f87ba8483e9ccf4b97da879ef1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d702123da9e48129ff7557a02f72b99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_079761f87ba8483e9ccf4b97da879ef1",
      "placeholder": "​",
      "style": "IPY_MODEL_6eefd4e548024038b8e50141bdeef898",
      "value": "100%"
     }
    },
    "5dfa0e0da40b4ddda4e7dd26a4243622": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04e8eac584c947f8a4dd2e7ae9721dd7",
      "max": 102530333,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f0bcc1811e5b4fb49be83fd1bf52c557",
      "value": 102530333
     }
    },
    "6eefd4e548024038b8e50141bdeef898": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7ff93690eff6496ca0eaff04af2d197e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ac6009437a84a5d8868dbfa7a209924": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd231e88790d42bea6867aa556651c8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5d702123da9e48129ff7557a02f72b99",
       "IPY_MODEL_5dfa0e0da40b4ddda4e7dd26a4243622",
       "IPY_MODEL_f77ce4b2ae214c80984ba0b4fa2d2c14"
      ],
      "layout": "IPY_MODEL_7ff93690eff6496ca0eaff04af2d197e"
     }
    },
    "e9e980dc151b4fc3a242255c7f92dd34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f0bcc1811e5b4fb49be83fd1bf52c557": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f77ce4b2ae214c80984ba0b4fa2d2c14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ac6009437a84a5d8868dbfa7a209924",
      "placeholder": "​",
      "style": "IPY_MODEL_e9e980dc151b4fc3a242255c7f92dd34",
      "value": " 97.8M/97.8M [00:01&lt;00:00, 97.8MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
