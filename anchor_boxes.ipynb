{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Preparation-of-the-proposed-region-to-train-the-Fast-RCNN\" data-toc-modified-id=\"Preparation-of-the-proposed-region-to-train-the-Fast-RCNN-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preparation of the proposed region to train the Fast RCNN</a></span></li><li><span><a href=\"#Region-proposal-network\" data-toc-modified-id=\"Region-proposal-network-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Region proposal network</a></span></li><li><span><a href=\"#Training-RPN-network\" data-toc-modified-id=\"Training-RPN-network-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Training RPN network</a></span></li><li><span><a href=\"#Coco-dataset\" data-toc-modified-id=\"Coco-dataset-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Coco dataset</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to provide functions that produce anchor boxes as decribed in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A box will be describe either as a numpy array $[y^-, x^-, y^+, x^+]$  or as a numpy array $[c_y, c_x, h,w]$\n",
    "\n",
    "TODO : CHECK +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.279181Z",
     "start_time": "2021-12-08T23:11:58.115463Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches #In order to draw the box ! (je sais pas pourquoi j'Ã©cris en anglais)\n",
    "from torchvision import models\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.294254Z",
     "start_time": "2021-12-08T23:12:00.281183Z"
    }
   },
   "outputs": [],
   "source": [
    "def vertice_to_yxhw(anchor):\n",
    "    res = (np.mean((anchor[0],anchor[2])),np.mean((anchor[1],anchor[3])), anchor[2] - anchor[0] + 1, anchor[3] - anchor[1]+1)\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.310283Z",
     "start_time": "2021-12-08T23:12:00.296255Z"
    }
   },
   "outputs": [],
   "source": [
    "def yxhw_to_vertice(anchor):\n",
    "    res = (anchor[0] - anchor[2]/2, anchor[1] - anchor[3]/2, anchor[0] + anchor[2]/2, anchor[1] + anchor[3]/2)\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.326279Z",
     "start_time": "2021-12-08T23:12:00.312275Z"
    }
   },
   "outputs": [],
   "source": [
    "def anchor_box(center, ratio, scale, shape_initial, shape_featured):\n",
    "    sub_width = shape_initial[0]/shape_featured[0]\n",
    "    sub_height = shape_initial[1]/shape_featured[1]\n",
    "    anchor_width = sub_width*scale*np.sqrt(ratio)\n",
    "    anchor_height = sub_height*scale/np.sqrt(ratio)\n",
    "    \n",
    "    ym = center[1] - anchor_height/2\n",
    "    yp = center[1] + anchor_height/2\n",
    "    xm = center[0] - anchor_width/2\n",
    "    xp = center[0] + anchor_width/2\n",
    "    \n",
    "    anchor = np.array((ym,xm,yp,xp))\n",
    "    return(anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.341279Z",
     "start_time": "2021-12-08T23:12:00.328260Z"
    }
   },
   "outputs": [],
   "source": [
    "def list_centers(shape_initial, shape_featured):\n",
    "    ratio_h = shape_initial[1]/shape_featured[1]\n",
    "    ratio_w = shape_initial[0]/shape_featured[0]\n",
    "    #intiail center is the center at the left top corner\n",
    "    all_centers = [np.array((ratio_w/2, ratio_h/2),dtype=float) + np.array((ratio_w*i, ratio_h*j),dtype=float) for i in range(int(shape_featured[0])) for j in range(int(shape_featured[1]))]\n",
    "    return(all_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.356279Z",
     "start_time": "2021-12-08T23:12:00.343272Z"
    }
   },
   "outputs": [],
   "source": [
    "def anchor_boxes(list_ratios, list_scales, shape_initial, shape_featured):\n",
    "    list_center = list_centers(shape_initial, shape_featured)\n",
    "    all_anchors = [anchor_box(center, ratio, scale,shape_initial,shape_featured) for center in list_center for ratio in list_ratios\n",
    "                   for scale in list_scales]\n",
    "    return(all_anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.372270Z",
     "start_time": "2021-12-08T23:12:00.358270Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_anchor_inside(anchor_box, shape_initial):\n",
    "    ym = anchor_box[0]\n",
    "    yp = anchor_box[2]\n",
    "    xm = anchor_box[1]\n",
    "    xp = anchor_box[3]\n",
    "    is_inside = (min(xm,xp)>0) & (max(xm,xp)<shape_initial[0]) & (max(yp,ym) < shape_initial[1]) & (min(ym,yp) > 0) \n",
    "    return(is_inside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.387270Z",
     "start_time": "2021-12-08T23:12:00.374270Z"
    }
   },
   "outputs": [],
   "source": [
    "def iou(box1,box2):\n",
    "    xm = max(box1[1], box2[1])\n",
    "    xp = min(box1[3], box2[3])\n",
    "    ym = max(box1[0], box2[0])\n",
    "    yp = min(box1[2], box2[2])\n",
    "    \n",
    "    intersection = 0\n",
    "    \n",
    "    if((xm < xp) &(ym < yp)):\n",
    "        intersection = (xp - xm)*(yp-ym)\n",
    "    \n",
    "    union = (box1[3]-box1[1])*(box1[2] - box1[0]) + (box2[3]-box2[1])*(box2[2] - box2[0]) - intersection\n",
    "    return(intersection/union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.403279Z",
     "start_time": "2021-12-08T23:12:00.391276Z"
    }
   },
   "outputs": [],
   "source": [
    "def iou_anchors_vs_gtbox(list_anchors, list_gt_box):\n",
    "    res = np.transpose([[iou(anchor, gt_box) for anchor in list_anchors] for gt_box in list_gt_box])\n",
    "    return(np.array(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** : changer la forme de cette fonction en utilisant que des *arrays*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.419270Z",
     "start_time": "2021-12-08T23:12:00.406270Z"
    }
   },
   "outputs": [],
   "source": [
    "#Return an array with :\n",
    "#for all ground truth box, the anchors which maximize the IOU with it\n",
    "#for all anchor, the max of the IOU\n",
    "\n",
    "#the first column of the array is the index and the last the IOU \n",
    "def best_anchors_from_iou(dt_anchors_vs_gtbox):\n",
    "    #index highest by gtbox (cond a)\n",
    "    dt_anchors_vs_gtbox.argmax(axis = 0)\n",
    "    ind_argmax = np.where(dt_anchors_vs_gtbox == dt_anchors_vs_gtbox.max(axis = 0))[0]\n",
    "    cond_a = dt_anchors_vs_gtbox[ind_argmax,:].max(axis = 1)\n",
    "    \n",
    "    #highest by anchors box (cond b)\n",
    "    index = dt_anchors_vs_gtbox.argmax(axis = 1)\n",
    "    iou_max = dt_anchors_vs_gtbox.max(axis = 1)\n",
    "    cond_b = dt_anchors_vs_gtbox[np.arange(dt_anchors_vs_gtbox.shape[0]),index]\n",
    "    \n",
    "    index_res = np.concatenate((ind_argmax,np.arange(dt_anchors_vs_gtbox.shape[0])))\n",
    "    res = np.concatenate((cond_a, cond_b), axis=0)\n",
    "    res = np.column_stack((index_res,res))\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.434260Z",
     "start_time": "2021-12-08T23:12:00.421270Z"
    }
   },
   "outputs": [],
   "source": [
    "#label_from_iou returns a np.array containing for each anchor its label. (+1 if foreground, 0 if background and -1 if not used\n",
    "#during the learning phase)\n",
    "#The default thresholds are defined according the original paper about Fatest RCNN.\n",
    "\n",
    "def label_from_iou(dt_anchors_vs_gtbox,pos_threshold = 0.7, neg_threshold = 0.3):\n",
    "    label = np.full(dt_anchors_vs_gtbox.shape[0],-1)\n",
    "    iou_max = dt_anchors_vs_gtbox.max(axis = 1)\n",
    "    #positive labels : 1\n",
    "    label[iou_max > pos_threshold] = 1\n",
    "    #negative labels : 0\n",
    "    label[iou_max < neg_threshold] = 0\n",
    "    #for anchors whose maximize IOU for a given object : +1\n",
    "    dt_anchors_vs_gtbox.argmax(axis = 0)\n",
    "    ind_argmax = np.where(dt_anchors_vs_gtbox == dt_anchors_vs_gtbox.max(axis = 0))[0]\n",
    "    label[ind_argmax] = 1\n",
    "    return(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.449260Z",
     "start_time": "2021-12-08T23:12:00.436260Z"
    }
   },
   "outputs": [],
   "source": [
    "def loc(anchor_box, gt_box):\n",
    "    anchor_box = vertice_to_yxhw(anchor_box)\n",
    "    gt_box = vertice_to_yxhw(gt_box)\n",
    "    \n",
    "    y = (gt_box[0] - anchor_box[0])/anchor_box[2]\n",
    "    x = (gt_box[1] - anchor_box[1])/anchor_box[3]\n",
    "    w = np.log(gt_box[3]/anchor_box[3])\n",
    "    h = np.log(gt_box[2]/anchor_box[2])\n",
    "    \n",
    "    return np.array((y,x,h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.465251Z",
     "start_time": "2021-12-08T23:12:00.451274Z"
    }
   },
   "outputs": [],
   "source": [
    "def deloc(anchor_box, reparam_box):\n",
    "    anchor_box = vertice_to_yxhw(anchor_box)\n",
    "    y = anchor_box[0] + (reparam_box[0] * anchor_box[2])\n",
    "    x = anchor_box[1] + (reparam_box[1] * anchor_box[3])\n",
    "    h = np.exp(reparam_box[2])*anchor_box[2]\n",
    "    w = np.exp(reparam_box[3])*anchor_box[3]\n",
    "    return np.array((y,x,h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.481256Z",
     "start_time": "2021-12-08T23:12:00.467253Z"
    }
   },
   "outputs": [],
   "source": [
    "def reparam_all_anchors(list_anchors, list_gt_box,pos_threshold = 0.7, neg_threshold = 0.3):\n",
    "    iou = iou_anchors_vs_gtbox(list_anchors, gt_box)\n",
    "    index_max_gtbox = iou.argmax(axis = 1)\n",
    "    gt_box_by_anchors = [list_gt_box[i] for i in index_max_gtbox]\n",
    "    #suboptimal\n",
    "    res = [loc(anchor, gt_box) for anchor,gt_box in zip(list_anchors, gt_box_by_anchors)] \n",
    "    #compute labels\n",
    "    labels = label_from_iou(iou, pos_threshold, neg_threshold)\n",
    "    return res,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.497279Z",
     "start_time": "2021-12-08T23:12:00.483259Z"
    }
   },
   "outputs": [],
   "source": [
    "def deparam_all_anchors(list_anchors, list_box_param):\n",
    "    res = [(deloc(anchor, box_param)) for anchor,box_param in zip(list_anchors, list_box_param)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.513279Z",
     "start_time": "2021-12-08T23:12:00.500252Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO : heck how to fill when\n",
    "\n",
    "def index_training_proposal(dt_anchors_vs_gtbox, nsize = 256, pos_ratio = 0.5,pos_threshold = 0.7, neg_threshold = 0.3):\n",
    "    #number of positive units we need to reach in the training sample (we want a balanced sample)\n",
    "    nb_pos_to_drawn = round(nsize*pos_ratio)\n",
    "    lab = label_from_iou(dt_anchors_vs_gtbox, pos_threshold, neg_threshold)\n",
    "    pos_lab = np.where(lab == 1)[0]\n",
    "    neg_lab = np.where(lab == 0)[0]\n",
    "    pos = len(pos_lab)\n",
    "    neg = len(neg_lab)\n",
    "    \n",
    "    if (pos > nb_pos_to_drawn):\n",
    "        disabled_index_pos = np.random.choice(pos_lab, size=(pos - nb_pos_to_drawn), replace = False)\n",
    "        lab[disabled_index_pos] = -1\n",
    "    \n",
    "    if (neg > nsize - nb_pos_to_drawn):\n",
    "        if(pos < nb_pos_to_drawn):\n",
    "            disabled_index_neg = np.random.choice(neg_lab, size=(neg - nsize + pos), replace = False)\n",
    "        else:\n",
    "            disabled_index_neg = np.random.choice(neg_lab, size=(neg + nb_pos_to_drawn - nsize), replace = False)\n",
    "        \n",
    "        lab[disabled_index_neg] = -1    \n",
    "    \n",
    "    res = np.where((lab == 0) | (lab == 1))[0]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.529260Z",
     "start_time": "2021-12-08T23:12:00.515270Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO : heck how to fill when\n",
    "\n",
    "def batch_training_proposal_RPN(image, feature_map, ratios, scales,gt_box,nsize = 256, pos_ratio = 0.5, pos_threshold = 0.7, neg_threshold = 0.3):\n",
    "    #define all anchors using the feature map and the initial picture shapes.\n",
    "    anchors_boxes = anchor_boxes(ratios, scales, image_torch.shape[2:], feature_torch.shape[2:])\n",
    "    #check if each box is inside the initial image\n",
    "    anchors_boxes = [box for box in anchors_boxes if check_anchor_inside(box, image_torch.shape[2:])]\n",
    "    #IOU anchors vs gt box\n",
    "    iou_anc_gt_box = iou_anchors_vs_gtbox(anchors_boxes, gt_box)\n",
    "    #Index of the units we keep\n",
    "    ind_for_sample = index_training_proposal(iou_anc_gt_box,nsize, pos_ratio)\n",
    "    anchors_boxes_reparam,lab_anchors = reparam_all_anchors(anchors_boxes,gt_box,pos_threshold, neg_threshold)\n",
    "    return ({\"image\" : image, \"boxes\" : torch.from_numpy(np.array(anchors_boxes_reparam)[ind_for_sample,:]),\n",
    "             \"labels\" : torch.from_numpy(lab_anchors[ind_for_sample])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:00.559249Z",
     "start_time": "2021-12-08T23:12:00.531283Z"
    }
   },
   "outputs": [],
   "source": [
    "image_torch = 800*torch.rand((1,3,800,800))\n",
    "feature_torch = torch.rand([1,512,50,50])\n",
    "\n",
    "ratio = [0.5, 1, 2]\n",
    "anchor_scales = [8, 16, 32]\n",
    "\n",
    "gt_box = [np.array([20, 30, 400, 500]), np.array([300, 400, 500, 600])]\n",
    "labels_gt_box = np.array((\"chien\",\"chat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:01.735330Z",
     "start_time": "2021-12-08T23:12:00.561252Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_rpn = batch_training_proposal_RPN(image_torch, feature_torch, ratio, anchor_scales, gt_box,256,0.5,0.7,0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of the proposed region to train the Fast RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:01.750681Z",
     "start_time": "2021-12-08T23:12:01.737311Z"
    }
   },
   "outputs": [],
   "source": [
    "def clip_predicted_boxes(list_box, th_min, th_max):\n",
    "    list_box = np.array(list_box)\n",
    "    return list(np.clip(list_box,th_min,th_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:01.766679Z",
     "start_time": "2021-12-08T23:12:01.752679Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove all boxes with at least the width or the height less that 16\n",
    "def boxes_hw_min(list_box, list_score, min_size = 16):\n",
    "    boxes = np.array(list_box)\n",
    "    height = boxes[:, 2] - boxes[:, 0]\n",
    "    width = boxes[:, 3] - boxes[:, 1]\n",
    "    box_kept = np.where((height > min_size) & (width > min_size))[0]\n",
    "    list_box_kept = [list_box[j] for j in box_kept]\n",
    "    list_score = [list_score[j] for j in box_kept]\n",
    "    return list_box_kept, list_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:01.782680Z",
     "start_time": "2021-12-08T23:12:01.768698Z"
    }
   },
   "outputs": [],
   "source": [
    "def nms(list_box, list_score, top_pre, top_post, thresold):\n",
    "    list_score = np.array(list_score)\n",
    "    order = list_score.argsort()[::-1]\n",
    "    order = order[:top_pre]\n",
    "    keep = []\n",
    "    list_box = np.array(list_box)\n",
    "    \n",
    "    ym = list_box[:,0]\n",
    "    xm = list_box[:,1]\n",
    "    yp = list_box[:,2]\n",
    "    xp = list_box[:,3]\n",
    "    areas = (xp - xm + 1) * (yp - ym + 1)\n",
    "\n",
    "    while len(order)>0:\n",
    "        i = order[0]\n",
    "        yym = np.maximum(ym[i], ym[order[1:]])\n",
    "        xxm = np.maximum(xm[i], xm[order[1:]])\n",
    "        yyp = np.minimum(yp[i], yp[order[1:]])\n",
    "        xxp = np.minimum(xp[i], xp[order[1:]])\n",
    "        \n",
    "        width = np.maximum(0.0, xxp - xxm + 1)\n",
    "        height = np.maximum(0.0, yyp - yym + 1)\n",
    "        intersection = width*height\n",
    "        ovr = intersection/(areas[i] + areas[order[1:]] - intersection)\n",
    "        \n",
    "        ind_to_keep = np.where(ovr <= thresold)[0]\n",
    "        order = order[ind_to_keep + 1]\n",
    "        keep.append(i)\n",
    "    \n",
    "    keep = keep[:top_post]\n",
    "    return(list_box[keep,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region proposal network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:44.975470Z",
     "start_time": "2021-12-08T23:12:44.966089Z"
    }
   },
   "outputs": [],
   "source": [
    "#boxes as tensor [N, 5]\n",
    "def roi_pooling(boxes, feature_map,scale,adaptative_max_pool):\n",
    "    boxes_coord = boxes[:,1:].mul(scale).long() #scale + round\n",
    "    res = [feature_map.narrow(0, boxes[i,0].int(),1)[..., boxes_coord[i,1]:(boxes_coord[i,3]+1), boxes_coord[i,0]:(boxes_coord[i,2]+1)] for i in range(boxes_coord.shape[0])]\n",
    "    res = [adaptative_max_pool(element) for element in res]\n",
    "    res = torch.cat(res, axis = 0)\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:53.742770Z",
     "start_time": "2021-12-08T23:12:53.724769Z"
    }
   },
   "outputs": [],
   "source": [
    "#0 in labels_gt_box must be the background\n",
    "def batch_training_proposal_FastRCNN(feature_map,list_box,list_gt_box,labels_gt_box, nsize = 128, pos_ratio = 0.25, pos_iou_threshold = 0.5,\n",
    "                                    neg_iou_threshold_p = 0.5, neg_iou_threshold_n = 0.0, adaptative_max_pool = torch.nn.AdaptiveMaxPool2d((7,7),return_indices=False),scale = 1):\n",
    "    #compute iou between each pair\n",
    "    dt_anchors_vs_gtbox = iou_anchors_vs_gtbox(list_box,list_gt_box)\n",
    "    \n",
    "    #number of positive units we need to reach in the training sample (we want a balanced sample)\n",
    "    nb_pos_to_drawn = round(nsize*pos_ratio)\n",
    "    iou = iou_anchors_vs_gtbox(roi_pred, gt_box)\n",
    "    #compute the maximum for each anchor\n",
    "    gt_roi_label = np.argmax(iou, axis = 1)\n",
    "    gt_roi_max = np.max(iou, axis = 1)\n",
    "    labels = labels_gt_box[gt_roi_label]\n",
    "    \n",
    "    #assign the label if greater that pos_iou_threshold\n",
    "    #assign background if between the two negative thresholds\n",
    "    gt_pos = np.where((gt_roi_max > pos_iou_threshold))[0]\n",
    "    gt_neg = np.where((gt_roi_max < neg_iou_threshold_p) & (gt_roi_max > neg_iou_threshold_n))[0] #background -- 0\n",
    "\n",
    "    #Nb of positives and negatives boxes get using the thresholds\n",
    "    pos = len(gt_pos)\n",
    "    neg = len(gt_neg)\n",
    "    \n",
    "    #Subsampling from it\n",
    "    if (pos > nb_pos_to_drawn):\n",
    "        disabled_index_pos = np.random.choice(range(len(gt_pos)), size=(pos - nb_pos_to_drawn), replace = False)\n",
    "        gt_pos = np.delete(gt_pos, disabled_index_pos)\n",
    "    \n",
    "    if (neg > nsize - nb_pos_to_drawn):\n",
    "        if(pos < nb_pos_to_drawn):\n",
    "            disabled_index_neg = np.random.choice(range(len(gt_neg)), size=(neg - nsize + pos), replace = False)\n",
    "            gt_neg = np.delete(gt_neg, disabled_index_neg)\n",
    "        else:\n",
    "            disabled_index_neg = np.random.choice(range(len(gt_neg)), size=(neg + nb_pos_to_drawn - nsize), replace = False)\n",
    "            gt_neg = np.delete(gt_neg, disabled_index_neg)\n",
    "        \n",
    "    \n",
    "    #if negative : assign background labels with it's \"0\"\n",
    "    labels[gt_neg] = \"0\"\n",
    "    final_index = np.append(gt_pos,gt_neg)\n",
    "    \n",
    "    #Non reparams\n",
    "    non_reparam = np.array(list_box)[final_index,:]\n",
    "    #Need to transform from yxhw to xywh\n",
    "    non_reparam = non_reparam[:,(1,0,3,2)]\n",
    "    non_reparam = np.hstack((np.zeros((non_reparam.shape[0],1)), non_reparam))\n",
    "    non_reparam = torch.from_numpy(non_reparam)\n",
    "    data_for_training =roi_pooling(non_reparam, feature_map,scale, adaptive_max_pool)\n",
    "    #Reparams\n",
    "    reparam = [loc(box,gt_box) for box,gt_box in zip(non_reparam, list(np.array(list_gt_box)[gt_roi_label,:]))]\n",
    "    \n",
    "    return  data_for_training, reparam,labels[final_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:13:26.269414Z",
     "start_time": "2021-12-08T23:13:26.260394Z"
    }
   },
   "outputs": [],
   "source": [
    "#data_x, box_y, label_y = batch_training_proposal_FastRCNN(test,roi_pred,gt_box,labels_gt_box, nsize = 128, pos_ratio = 0.25, pos_iou_threshold = 0.5,\n",
    "#                                    neg_iou_threshold_p = 0.5, neg_iou_threshold_n = 0.0,adaptative_max_pool = torch.nn.AdaptiveMaxPool2d((7,7),return_indices=False),\n",
    "#                                 scale = 1/16.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training RPN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:13:37.687322Z",
     "start_time": "2021-12-08T23:13:37.348201Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "image_torch = 800*torch.rand((1,3,800,800))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:13:40.926536Z",
     "start_time": "2021-12-08T23:13:40.493540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 200, 200])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We choose the place where we extracted the feature map in order to get H_feature * W_feature around 2400 (papers)\n",
    "resnet50_features = nn.Sequential(*(list(resnet50.children())[:-5]))\n",
    "resnet50_features(image_torch).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/69480764/what-is-the-difference-between-resnet50-vgg16-etc-and-rcnn-faster-rcnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:13:41.640996Z",
     "start_time": "2021-12-08T23:13:41.621664Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class RPN(nn.Module):\n",
    "    #TODO : remove embedding_dim using wv.shape[1]\n",
    "    #define all the layers used in model\n",
    "    def __init__(self,mid_channel, in_channels,nb_anchors,pre_trained_model):\n",
    "        \n",
    "        #Constructor\n",
    "        super().__init__()        \n",
    "        \n",
    "        #embedding layer\n",
    "        self.pre_trained_model = pre_trained_model\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, 3, 1, 1)\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv1.bias.data.zero_()\n",
    "        \n",
    "        self.reg_layer = nn.Conv2d(mid_channels, n_anchor *4, 1, 1, 0)\n",
    "        self.reg_layer.weight.data.normal_(0, 0.01)\n",
    "        self.reg_layer.bias.data.zero_()\n",
    "\n",
    "        self.cls_layer = nn.Conv2d(mid_channels, n_anchor *2, 1, 1, 0)\n",
    "        # classification layer\n",
    "        self.cls_layer.weight.data.normal_(0, 0.01)\n",
    "        self.cls_layer.bias.data.zero_()\n",
    "       \n",
    "\n",
    "    def forward(self,img):\n",
    "        x = self.pre_trained_model(img)\n",
    "        x = self.conv1(x)\n",
    "        pred_anchor = self.reg_layer(x)\n",
    "        pred_anchor = pred_anchor.permute(0, 2, 3, 1).contiguous().view(1, -1, 4)\n",
    "        \n",
    "        pred_cls = self.cls_layer(x)\n",
    "        pred_cls = pred_cls.permute(0, 2, 3, 1).contiguous()\n",
    "        pred_cls = pred_cls.view(1, -1, 2)\n",
    "\n",
    "        return pred_anchor, pred_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:13:52.294384Z",
     "start_time": "2021-12-08T23:13:52.196399Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28224, 4])\n",
      "torch.Size([1, 28224, 2])\n"
     ]
    }
   ],
   "source": [
    "model = RPN(256,256,9,resnet50_features)\n",
    "image_torch = 800*torch.rand((1,3,224,224)) #scale picture ? mean ? \n",
    "res = model(image_torch)\n",
    "\n",
    "print(res[0].shape)\n",
    "print(res[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coco dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:02.198676Z",
     "start_time": "2021-12-08T23:11:58.174Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:02.198676Z",
     "start_time": "2021-12-08T23:11:58.176Z"
    }
   },
   "outputs": [],
   "source": [
    "# The directory containing the source images\n",
    "data_path = \"data/instance_version/train\"\n",
    "\n",
    "# The path to the COCO labels JSON file\n",
    "labels_path = \"data/instance_version/instances_train_trashcan.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:02.200680Z",
     "start_time": "2021-12-08T23:11:58.178Z"
    }
   },
   "outputs": [],
   "source": [
    "class CocoDetection_diy(data.Dataset) :\n",
    "    \"\"\"`MS Coco Detection <http://mscoco.org/dataset/#detections-challenge2016>`_ Dataset.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory where images are downloaded to.\n",
    "        annFile (string): Path to json annotation file.\n",
    "        resize : (int,int) size of the images wanted \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, annFile, size):\n",
    "        from pycocotools.coco import COCO\n",
    "        self.root = root\n",
    "        self.coco = COCO(annFile)\n",
    "        self.ids = list(self.coco.imgs.keys())\n",
    "        self.size = size\n",
    "        self.transform = transforms.Compose([transforms.Resize(size), transforms.transforms.ToTensor()])\n",
    "\n",
    "       # transforms.Compose([\n",
    "       # transforms.Resize(256),\n",
    "       # transforms.CenterCrop(224),\n",
    "       # transforms.ToTensor(),\n",
    "       # transforms.Normalize(\n",
    "       # mean=[0.485, 0.456, 0.406],\n",
    "       # std=[0.229, 0.224, 0.225]\n",
    "   # )])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: Tuple (image, target). target is the object returned by ``coco.loadAnns``.\n",
    "        \"\"\"\n",
    "        coco = self.coco\n",
    "        img_id = self.ids[index]\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        target = coco.loadAnns(ann_ids)\n",
    "\n",
    "        path = coco.loadImgs(img_id)[0]['file_name']\n",
    "\n",
    "        # Resize des images :\n",
    "        img = Image.open(os.path.join(self.root, path)).convert('RGB')\n",
    "        original_size = img.size\n",
    "        img = self.transform(img)\n",
    "\n",
    "        # Targets :\n",
    "        t = []\n",
    "        for elem in target :  \n",
    "          box = elem['bbox']\n",
    "          box[0] *= self.size[0] / original_size[0]\n",
    "          box[1] *= self.size[1] / original_size[1]\n",
    "          box[2] *= self.size[0] / original_size[0]\n",
    "          box[3] *= self.size[1] / original_size[1]\n",
    "          t.append(box+[elem['category_id']])\n",
    "\n",
    "        # Ajout de targets vides pour avoir le mÃªme nombre de targets partout (je ne sais pas si c'est nÃ©cÃ©ssaire)\n",
    "        #Khaled : il y en a dix au max ? \n",
    "        for i in range(10-len(t)) :\n",
    "            t.append([0,0,0,0,-1])\n",
    "\n",
    "        return img, t\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __repr__(self):\n",
    "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "        tmp = '    Transforms (if any): '\n",
    "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        tmp = '    Target Transforms (if any): '\n",
    "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        return fmt_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T23:12:02.201676Z",
     "start_time": "2021-12-08T23:11:58.180Z"
    }
   },
   "outputs": [],
   "source": [
    "instances_train = CocoDetection_diy(root = data_path, annFile = labels_path, size=(224,224))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat_app",
   "language": "python",
   "name": "stat_app"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
